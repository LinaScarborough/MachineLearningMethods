---
title: "Machine Learning Methods: a look into the dog register of the city of Zürich"
author: "Rina Gandolfi, Daniel Herrera & Lina Scarborough"
date: "2024-05-31"
output: 
  html_document:
    df_print: paged
    theme: "sandstone"
    citation_package: natbib
    css: "css/style.css"
    toc: true
    toc_float: true
bibliography: references.bib
link-citations: yes
runtime: shiny
---

<div style="text-align: center;">
  ![](Assets/banner_image_2.jpg){width=60%}
</div>

_Pet Paradise: a data-driven vision of growing dog population around Lake Zurich. AI-generated by our team._

```{r setup, include=FALSE}

# Load required libraries
# dplyr: For data manipulation
if (!require(dplyr, quietly = TRUE)) {
  install.packages("dplyr")
  library(dplyr)
}

# stringr: For string manipulation
if (!require(stringr, quietly = TRUE)) {
  install.packages("stringr")
  library(stringr)
}

# plotly: For interactive plots
if (!require(plotly, quietly = TRUE)) {
  install.packages("plotly")
  library(plotly)
}

# ggplot2: For data visualization
if (!require(ggplot2, quietly = TRUE)) {
  install.packages("ggplot2")
  library(ggplot2)
}

# readxl: For reading Excel files
if (!require(readxl, quietly = TRUE)) {
  install.packages("readxl")
  library(readxl)
}

# readr: For reading data
if (!require(readr, quietly = TRUE)) {
  install.packages("readr")
}
library(readr)

# treemapify: For creating treemaps
if (!require(treemapify, quietly = TRUE)) {
  install.packages("treemapify")
}
library(treemapify)

# scales: For scale functions
if (!require(scales, quietly = TRUE)) {
  install.packages("scales")
}
library(scales)

# patchwork: For combining ggplots
if (!require(patchwork, quietly = TRUE)) {
  install.packages("patchwork")
}
library(patchwork)

# gridExtra: For arranging plots
if (!require(gridExtra, quietly = TRUE)) {
  install.packages("gridExtra")
}
library(gridExtra)

# rcolorbrewer
if (!require(RColorBrewer, quietly = TRUE)) {
  install.packages("RColorBrewer")
}
library(RColorBrewer)

 # forcats
if (!require(forcats, quietly = TRUE)) {
  install.packages("forcats")
}
library(forcats)

 # shiny
if (!require(shiny, quietly = TRUE)) {
  install.packages("shiny")
}
library(shiny)

 # treemap
if (!require(treemap, quietly = TRUE)) {
  install.packages("treemap")
} 
library(treemap)

```

## 1. Introduction

### 1.1. Presentation of the case

We introduce Pet Paradise, a successful Zürich-based pet shop business, wants to expand. However, the owner is not aware of current and future customer needs. The owner has approached us to advise what predictions we can make about canine breeds, ages, neighborhood concentrations and distributions, to figure out where to open the next Pet Paradise branch and what products to offer there.

The objective of our report is to advise Pet Paradise and predict dog breed trends, in order to facilitate targeted marketing. Our analysis delves into canine and pet owner data. We have explored Zürich's neighborhoods to identify prevailing canine demographics and trends. So our predictive analysis extends beyond just current demographics to anticipate future trends, allowing Pet Paradise to stay ahead of evolving customer needs. 

By monitoring shifts in dog ownership patterns, breed popularity, and lifestyle preferences (size, number of dogs), Pet Paradise can adapt its product offerings and marketing strategies.

With our help, Pet Paradise can leverage data-driven insights to grow their business and help Zurich’s canines live to their best health and dog-happiness. We envision Pet Paradise expanding into other cantons too if they foster the customer satisfaction to shape Switzerland’s pet industry landscape.

### 1.2. Motivations

Dogs are an integral part of urban communities, with pet ownership having grown parallel to population over the past decades. Zürich and its canton boast the largest population of dogs of any Swiss region, as suggested by a 2013 study [@pospischil2013hundepopulation], proving the value of building a thorough data-driven interpretation of the markets associated with dog ownership. 

Additionally, in a report [@statistik1984hunde] by the Zürich City Police, historical records and concerns due to the environmental impact of an ever increasing canine population have led to stricter laws against dog-produced waste and specific taxing for dog owners. The implementation of dog registration procedures, which date back several hundred years, has facilitated the collection of valuable statistical data, which provides a glimpse into the relationship between owners and their pets across time (with owner personal information limitations, due to privacy concerns). The existence of such cohesive and easily available data has served as a strong motivating factor for our team to undertake the current project.

Moreover, our data science team consists of individuals who are deeply passionate about dogs, each with varying degrees of personal experience in pet ownership, and understand the importance of analyzing the current dynamics between humans and dogs in Switzerland from an analytic perspective.

### 1.3. Disclaimer

The analysis in this report is conducted purely for educational purposes, focusing solely on the statistical modeling and client recommendations. This means that within the confines of this project, sex values for an animal such as dogs and their human owners within the dataset are interpreted as binary. The findings presented here are not intended to reflect or endorse any particular social reflections related to sexual identity. We acknowledge that discussions surrounding sex identity are multifaceted for individuals and communities.

---

## 2. Data exploration

### 2.1. Data source and preparation

As mentioned above, the main data has been sourced from the dog register [@stadtzuerich2024hundebestande], having been collected and published by the Open Data Portal of the City Council of Zürich, under the name "Hundebestände der Stadt Zürich, seit 2015". The description of the data set from the original source is as follows:

_This dataset contains information on dogs and their owners from the municipal dog register since 2015. Information on the age group, Sex and statistical district of residence is provided for dog owners. The breed, breed type, sex, year of birth, age and color are recorded for each dog. The dog register is kept by the Dog Control Department of the Zurich City Police._

To ensure a seamless workflow and make variable interpretation easier for our group, we have undertaken several preparatory steps with the dataset. These include renaming columns and translating certain string values from German to English, along with performing some cleaning procedures.

The main source of data is the `kul100od1001.csv` file, which contains a collection of 70,967 dog registrations with 33 variables.

```{r loading, include=FALSE}

# Load dataset
df <- read.csv("Datasets/kul100od1001.csv")

```

For the English version, translations for the column names are defined and a function is employed to replace multiple patterns at once for content translation. This includes translations for age groups, sexes, breed types, and dog colors. After applying the translation function across all relevant columns, dog colors are also translated. From this point forward, we will refer to variables and items exclusively by their translated English names.

```{r translation, include=FALSE}

# Check if "Datasets/df_EN.csv" exists
if (!file.exists("Datasets/df_EN.csv")) {
  # Duplicate and rename df for English version
  df_EN <- df
  
  # Define translations for column names in English
  colnames(df_EN) <- c("KeyDateYear", "DataStatusCd", "OwnerId", "OwnerAgeGroupCd", "OwnerAgeGroup", "OwnerAgeGroupSort", "OwnerSexCd", "OwnerSex", "OwnerSexSort", "DistrictCd", "District", "DistrictSort", "QuarCd", "Quar", "QuarSort", "PrimaryBreed", "SecondaryBreed", "MixedBreedCd", "MixedBreed", "MixedBreedSort", "BreedTypeCd", "BreedType", "BreedTypeSort", "DogBirthYear", "DogAgeGroupCd", "DogAgeGroup", "DogAgeGroupSort", "DogSexCd", "DogSex", "DogSexSort", "DogColor", "NumberOfDogs")
  
  # Define a function to replace multiple patterns at once
  replace_patterns <- function(text, patterns, replacements) {
    for (i in seq_along(patterns)) {
      text <- str_replace_all(text, patterns[i], replacements[i])
    }
    return(text)
  }
  
  # Define patterns and replacements for content translation
  patterns <- c("- bis ", "-Jährige", "männlich", "weiblich", "Keine", "Unbekannt", "Rassehund", "Mischling, beide Rassen bekannt", "Mischling, sekundäre Rasse unbekannt", "Mischling, beide Rassen unbekannt", "Kleinwüchsig", "Rassentypenliste I", "Rassentypenliste II")
  replacements <- c(" to ", " years old", "male", "female", "none", "Unknown", "Pedigree dog", "Mixed breed, both breeds known", "Mixed breed, secondary breed unknown", "Mixed breed, both breeds unknown", "Small stature", "Breed type list I", "Breed type list II")
  
  # Apply the function across all columns
  df_EN[] <- lapply(df_EN, function(x) replace_patterns(x, patterns, replacements))
  
  # Color translation - can be further customized based on your dataset
  color_patterns <- c("schwarz", "braun", "weiss", "grau", "silber", "rot", "gelb", "hell", "dunkel", "gestromt", "schimmel", "zweifarbig", "dreifarbig", "vierfarbig", "gemischt", "meliert", "hirschrot mit Maske", "löwenfarbig")
  color_replacements <- c("black", "brown", "white", "gray", "silver", "red", "yellow", "light", "dark", "brindle", "mold", "2 colors", "3 colors", "4 colors", "mixed", "mottled", "stag red with mask", "lion-colored")
  
  # Translate dog colors
  df_EN$DogColor <- replace_patterns(df_EN$DogColor, color_patterns, color_replacements)
  
  write.csv(df_EN, "Datasets/df_EN.csv", row.names = FALSE)
  
} else {
  print("English version already saved")
}

```

The next step involves identifying and marking the initial occurrence of each `OwnerId` as unique within the dataset. This distinction facilitates further analyses that may require the identification of distinct entries.

```{r df_unique_OwnerId, include=FALSE}

# Clean import of dataset
df_EN <- read.csv("Datasets/df_EN.csv")

df_EN$unique_OwnerId <- !duplicated(df_EN$OwnerId)
head(df_EN)

```

Finally, a subset of relevant columns is extracted from the comprehensive dataset, creating a streamlined dataframe named `df_EN_EDA`. The subset includes essential fields such as `KeyDateYear`, `OwnerId`, and details regarding the dogs, including `PrimaryBreed` and `DogBirthYear`. Additionally, the `NumberOfDogs` column is converted from its original format to a numeric type, ensuring that subsequent data analysis can utilize numerical operations.

```{r df_EN_EDA, include=FALSE}

df_EN_EDA <- df_EN %>%
  dplyr::select(KeyDateYear, OwnerId, OwnerAgeGroup, OwnerSex, DistrictSort, QuarCd, PrimaryBreed, SecondaryBreed, MixedBreed, BreedType, DogBirthYear, DogAgeGroupCd, DogSex, NumberOfDogs, unique_OwnerId) %>%
  mutate(NumberOfDogs = as.numeric(as.character(NumberOfDogs))) %>% # Convert NumberOfDogs to numeric
  mutate(across(where(is.character), factor)) %>%
  mutate_at(vars(DistrictSort, QuarCd), factor)

```

We begin with a summary of the data, providing an overview of its structure and contents.


```{r structure, include=TRUE}

# Load dataset
str(df_EN)

```

As can be seen in the structure of the data, the set comprises several observations of diverse data types. Most variables are expressed three times as different types, as integers (coded and sorted form), as well as strings (text). Depending on their implementation in the study they have been selected in one of the three variants, therefore our selection of relevant observations can be summarized as follows:

**Numerical values**:

  - `KeyDateYear`: numerical value for the reference year
  - `OwnerId`: numerical identifier for the owner of the registered dog
  - `OwnerAgeGroup`: referring to the owner's age as a 10-year category
  - `DogBirthYear`: numerical value for the birth year of the dog
  - `DogAgeGroupSort`: referring to the dog's age at the time of registration
  - `NumberOfDogs`: numerical counter of the dog count for each dog owner 
  
**Binary variables**: 

  - `DogSexText`: numerical value indicating two states for the biological sex of the dog
  
**String values**:

  - `District`: the name of each larger district of Zürich according to the official division
  - `Quar`: the name of the smaller neighborhoods which comprise the larger districts
  - `PrimaryBreed` and `SecondaryBreed`: referring to dog race denominations and information
  - `MixedBreed`: additional information regarding race mixing in the dog
  - `DogColor`: a descriptive name for the color of the dog
  - `BreedType`: referring to the official dog type classification according to the dog ordinance [@zh2009hundeverordnung]

---

### 2.2. Exploratory Data Analysis

#### 2.2.1. Analyzing Diversity in Dataset Features: Years, Owner IDs, and Age Groups

This series of R code snippets delves into the examination of key
features within the `df_EN_EDA` dataframe, focusing on the identification and
analysis of unique entries for `KeyDateYear`, `OwnerId`, and `OwnerAgeGroup`.
Each code section is designed to extract unique values, count these
entries, and where applicable, visualize the distribution. Such analysis
is integral for understanding the dataset's diversity across different
dimensions, helping to highlight temporal coverage, ownership
uniqueness, and demographic variations among owners.

```{r unique_years, include=TRUE}

# Extract and count unique years
unique_years <- unique(df_EN_EDA$KeyDateYear)
number_of_unique_years <- length(unique_years)
print(number_of_unique_years)
print(unique_years)

```

```{r unique_OwnerId, include=TRUE}

# Extract and count unique Owner IDs
unique_Owner <- unique(df_EN_EDA$OwnerId)
number_of_unique_Owner <- length(unique_Owner)
print(number_of_unique_Owner)

```

#### 2.2.2. Unique owners by year, by age group and by sex

This section presents an interactive visualization that displays unique owner IDs by age group and sex for a selected year. The user interface allows the selection of a year and a sex, and the resulting plot shows the distribution of unique Owner IDs across different age groups based on the chosen criteria.

```{r shiny, unique owners by year, by age group and by Sex, echo=FALSE, message=FALSE, warning=FALSE}

# Define UI
ui <- fluidPage(
    sidebarLayout(
        sidebarPanel(
            selectInput("selectedYear", "Select Year:", 
                        choices = unique(df_EN_EDA$KeyDateYear)),
            selectInput("selectedSex", "Select Sex:",
                        choices = c("All" = "all", "Male" = "male", "Female" = "female")),
            helpText("Displays unique owner IDs by age group and selected sex for the chosen year.")
        ),
        mainPanel(
            plotOutput("SexPlot")
        )
    )
)

# Define server logic
server <- function(input, output) {
    output$SexPlot <- renderPlot({
        # Aggregate unique Owner IDs by Age Group, Year, and Sex
        if (input$selectedSex == "all") {
            # Sum across both Sexs
            unique_owner_counts_Sex <- df_EN_EDA %>%
                group_by(KeyDateYear, OwnerAgeGroup) %>%
                summarise(UniqueOwnerCountSex = n_distinct(OwnerId), .groups = 'drop')
        } else {
            # Filter for a specific Sex
            unique_owner_counts_Sex <- df_EN_EDA %>%
                group_by(KeyDateYear, OwnerAgeGroup, OwnerSex) %>%
                summarise(UniqueOwnerCountSex = n_distinct(OwnerId), .groups = 'drop') %>%
                filter(OwnerSex == input$selectedSex)
        }

        # Adjust factor levels
        unique_owner_counts_Sex$OwnerAgeGroup <- factor(unique_owner_counts_Sex$OwnerAgeGroup,
                                                           levels = unique(df_EN_EDA$OwnerAgeGroup[order(df_EN_EDA$OwnerAgeGroup)]))

        # Filter data for the specific year
        data_for_year_Sex <- filter(unique_owner_counts_Sex, KeyDateYear == as.numeric(input$selectedYear))
        
        # Define gradient colors for discrete levels
        gradient_colors <- colorRampPalette(c("darkslategray2", "darkslategray"))(length(levels(unique_owner_counts_Sex$OwnerAgeGroup)))
        names(gradient_colors) <- levels(unique_owner_counts_Sex$OwnerAgeGroup)

        # Create the plot
        ggplot(data_for_year_Sex, aes(x = OwnerAgeGroup, y = UniqueOwnerCountSex, fill = OwnerAgeGroup)) +
            geom_bar(stat = "identity", position = "dodge") +
            geom_text(aes(label = UniqueOwnerCountSex), vjust = -0.5, color = "black", size = 3.5) +
            geom_hline(yintercept = c(100, 500, 1000, 1500), linetype = "dashed", color = "red") +
            theme_minimal() +
            labs(title = paste("Unique Owner IDs by Age Group and", input$selectedSex, "in", input$selectedYear),
                 x = "Owner Age Group",
                 y = "Count of Unique Owner IDs",
                 fill = "Owner Age Group") +
            scale_fill_manual(values = gradient_colors) +
            scale_y_continuous(limits = c(0, max(2000, max(data_for_year_Sex$UniqueOwnerCountSex) + 500)), breaks = seq(0, 2000, by = 500)) +
            scale_x_discrete(labels = function(x) {
                x <- gsub("[0-9]+ to [0-9]+ years old", "", x)
                gsub("Unknown", "", x)
            })
    })
}

shinyApp(ui = ui, server = server)

```

#### 2.2.3. Unique owners by age group over the years

The following visualization shows the count of unique owner IDs across different age groups over the years. The plot is generated by aggregating unique owner IDs by age group and year, adjusting factor levels, and creating a line plot.

```{r cs seasonal trend of Age Group, echo=FALSE, message=FALSE, warning=FALSE}

# Aggregate unique Owner IDs by Age Group and Year
unique_owner_counts <- df_EN_EDA %>%
  group_by(KeyDateYear, OwnerAgeGroup) %>%
  summarise(UniqueOwnerCount = n_distinct(OwnerId), .groups = 'drop')

# Adjust factor levels in the aggregated data before plotting
unique_owner_counts <- unique_owner_counts %>%
  arrange(desc(UniqueOwnerCount)) %>%
  mutate(OwnerAgeGroup = factor(OwnerAgeGroup, levels = unique(df_EN_EDA$OwnerAgeGroup[order(df_EN_EDA$OwnerAgeGroup)])),
         KeyDateYear = as.numeric(as.character(KeyDateYear)))  # Convert KeyDateYear to numeric

# Define gradient colors for discrete levels
gradient_colors <- colorRampPalette(c("darkslategray2", "darkslategray"))(length(levels(unique_owner_counts$OwnerAgeGroup)))
names(gradient_colors) <- levels(unique_owner_counts$OwnerAgeGroup)

# Create the line plot for all years with a line per age group
p <- ggplot(unique_owner_counts, aes(x = KeyDateYear, y = UniqueOwnerCount, group = OwnerAgeGroup, color = OwnerAgeGroup)) +
  geom_line(size = 1) +  # Add line
  geom_point(size = 3) +  # Add points
  geom_hline(yintercept = c(100, 500, 1000, 1500, 2000), linetype = "dashed", color = "red") +
  theme_minimal() +
  labs(x = "Year",
       y = "Count of Unique Owner IDs",
       color = "Owner Age Group") +  # Label for the legend
  scale_color_manual(values = gradient_colors) +  # Use gradient colors
  scale_y_continuous(limits = c(0, 2500), breaks = seq(0, 2500, by = 500)) +
  scale_x_continuous(breaks = seq(min(unique_owner_counts$KeyDateYear), max(unique_owner_counts$KeyDateYear), by = 1))  # Define breaks in the x-axis scale to show each year

# Print the plot
ggplotly(p)

```

#### 2.2.4. Yearly dog counts

After confirming successful conversion, we aggregated the data to compute the total number of dogs per year. The resulting counts were then visualized using histograms to illustrate the distribution over the years.

Furthermore, to understand the trend in dog population over time, we calculated the percentage change between consecutive years. This allowed us to identify any notable fluctuations or patterns in the data.

```{r shiny, yearly dog counts, echo=FALSE, message=FALSE, warning=FALSE}

df_EN_EDA2 <- df_EN_EDA

# Convert NumberOfDogs to numeric
df_EN_EDA2 <- df_EN_EDA2 %>% 
  mutate(NumberOfDogs = as.numeric(NumberOfDogs))

# Check for any conversion problems
sum(is.na(df_EN_EDA2$NumberOfDogs))

# Convert KeyDateYear to numeric
df_EN_EDA2$KeyDateYear <- as.numeric(as.character(df_EN_EDA2$KeyDateYear))

# Aggregate data to get total number of dogs per year
yearly_dog_counts <- df_EN_EDA2 %>%
  group_by(KeyDateYear) %>%
  summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop')

# Calculate the percentage change for annotations
yearly_dog_counts <- yearly_dog_counts %>%
  arrange(KeyDateYear) %>%
  mutate(Change = c(NA, diff(TotalDogs)),
         PercentChange = Change / lag(TotalDogs) * 100)

# Define UI
ui <- fluidPage(
  sidebarLayout(
    sidebarPanel(
      helpText("Click on a year in the bar plot to see the percentage change in dog registrations."),
      plotOutput("dogPlot", click = "plot_click"),
      verbatimTextOutput("click_info")
    ),
    mainPanel(
      plotOutput("dogChangePlot")
    )
  )
)

# Define server logic
server <- function(input, output) {
  output$dogPlot <- renderPlot({
    ggplot(yearly_dog_counts, aes(x = KeyDateYear, y = TotalDogs)) +
      geom_col(fill = "darkseagreen") +
      geom_hline(yintercept = c(2500, 5000, 7500), linetype = "dashed", color = "red") +  
      theme_minimal() +
      labs(title = "Total Number of Dogs per Year",
           x = "Year",
           y = "Total Number of Dogs") +
      scale_x_continuous(breaks = yearly_dog_counts$KeyDateYear, 
                         labels = yearly_dog_counts$KeyDateYear) +  
      scale_y_continuous(labels = scales::comma, 
                         breaks = seq(0, 10000, by = 1000),
                         limits = c(0, 10000)) + 
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
  })
  
  output$click_info <- renderPrint({
    if (!is.null(input$plot_click)) {
      year_clicked <- round(input$plot_click$x)
      year_data <- yearly_dog_counts %>%
        filter(KeyDateYear == year_clicked)
      if (nrow(year_data) > 0) {
        cat("Year:", year_data$KeyDateYear, "\n")
        cat("Total Dogs:", year_data$TotalDogs, "\n")
        cat("Percentage Change:", sprintf("%.1f%%", year_data$PercentChange), "\n")
      } else {
        cat("No data available for the selected year.")
      }
    }
  })
  
  output$dogChangePlot <- renderPlot({
    ggplot(yearly_dog_counts, aes(x = KeyDateYear, y = TotalDogs)) +
      geom_col(fill = "darkseagreen") +
      geom_hline(yintercept = c(2500, 5000, 7500), linetype = "dashed", color = "red") +  
      geom_smooth(method = "lm", color = "red", linetype = "dashed", se = FALSE) +  
      geom_text(data = yearly_dog_counts, aes(label = sprintf("%.1f%%", PercentChange)), 
                vjust = -1.5, hjust = 0.5, color = "darkgreen", size = 3.5) +
      theme_minimal() +
      labs(title = "Total Number of Dogs per Year",
           x = "Year",
           y = "Total Number of Dogs") +
      scale_x_continuous(breaks = yearly_dog_counts$KeyDateYear) +
      scale_y_continuous(labels = scales::comma, 
                         breaks = seq(0, 10000, by = 1000),  
                         limits = c(0, 10000)) +  
      theme(axis.text.x = element_text(angle = 45, hjust = 1),
            legend.position = "bottom")
  })
}

shinyApp(ui = ui, server = server)

```


#### 2.2.5. Heatmap of total number of registered dogs per year 

A heatmap was created to illustrate the distribution of dogs based on the sex and age group of their owners across different years. The data was organized by grouping it according to the year, owner's age group, and Sex. Separate heatmaps were generated for each year to visualize the data for that specific period.

Each heatmap represents the total number of dogs in various age groups, categorized by the Sex of their owners. The color gradient within the heatmap indicates the intensity of dog ownership, with warmer colors representing higher dog counts.

```{r shiny, heatmap, echo=FALSE, message=FALSE, warning=FALSE}

ui <- fluidPage(
    sidebarLayout(
        sidebarPanel(
            selectInput("selectedYear", "Select Year:", 
                        choices = unique(df_EN_EDA$KeyDateYear)),
            helpText("Displays a heatmap of unique owner counts by age group and sex for the selected year.")
        ),
        mainPanel(
            plotOutput("ownerHeatmap")
        )
    )
)

server <- function(input, output) {
    output$ownerHeatmap <- renderPlot({
        # Filter data for the specific year selected by user
        df_subset <- df_EN_EDA[df_EN_EDA$KeyDateYear == as.numeric(input$selectedYear), ]

        # Prepare the data
        owner_counts <- df_subset %>%
          distinct(KeyDateYear, OwnerAgeGroup, OwnerSex, OwnerId) %>%
          group_by(OwnerAgeGroup, OwnerSex) %>%
          summarize(UniqueOwners = n(), .groups = 'drop')

        # Create the heatmap
        p <- ggplot(owner_counts, aes(x = OwnerSex, y = OwnerAgeGroup, fill = UniqueOwners)) +
            geom_tile() +
            scale_fill_gradientn(colors = brewer.pal(11, "Spectral"), 
                                  limits = c(0, max(owner_counts$UniqueOwners, na.rm = TRUE)), 
                                  name = "Total Owners") +
            theme_minimal() +
            labs(title = paste("Heatmap of Unique Owners by Sex and Age Group", input$selectedYear),
                 x = "Owner's Sex",
                 y = "Owner's Age Group",
                 fill = "Number of Unique Owners") +
            theme(axis.text.y = element_text(angle = 45, hjust = 1))
        
        # Return the plot
        p
    })
}

shinyApp(ui = ui, server = server)

```

#### 2.2.6. Total count of dogs

##### 2.2.6.1. Total count of dogs by district

The annual distribution of dog registrations across various districts is examined using an interactive Shiny application. Users can select a year to view the total count of dogs by district for that specific year. The data is processed and visualized to provide insights into the distribution patterns over time.

```{r shiny, total count of dogs by district, echo=FALSE, message=FALSE, warning=FALSE}

ui <- fluidPage(
    sidebarLayout(
        sidebarPanel(
            selectInput("selectedYear", "Select Year:", 
                        choices = unique(df_EN_EDA$KeyDateYear)),
            helpText("Displays the total count of dogs by district for the selected year.")
        ),
        mainPanel(
            plotOutput("dogPlot")
        )
    )
)

server <- function(input, output) {
    output$dogPlot <- renderPlot({
        # Filter and aggregate data based on the selected year, excluding District 15
        yearly_data <- df_EN_EDA %>%
            filter(KeyDateYear == as.numeric(input$selectedYear), !is.na(DistrictSort), DistrictSort != "15") %>%
            group_by(DistrictSort) %>%
            summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
            arrange(desc(TotalDogs))  # Arrange by TotalDogs in descending order

        # Create the bar plot
        p <- ggplot(yearly_data, aes(x = reorder(DistrictSort, -TotalDogs), y = TotalDogs)) +
            geom_col(fill = "darkseagreen") +
            geom_text(aes(label = TotalDogs), vjust = -0.3, color = "black", size = 3.5) +  # Add dog counts on bars
            geom_hline(yintercept = c(100, 500, 1000, 1500), linetype = "dashed", color = "red") +
            scale_y_continuous(limits = c(0, 2000), breaks = seq(0, 2000, by = 500)) +
            theme_minimal() +
            labs(title = paste("Total Count of Dogs by District in", input$selectedYear),
                 x = "District",
                 y = "Total Number of Dogs") +
            theme(axis.text.x = element_text(angle = 0, hjust = 1),
                  legend.position = "none")
        
        return(p)
    })
}

shinyApp(ui = ui, server = server)

```

##### 2.2.6.2. Total count of dogs by district with dog's sex

To enhance understanding of the distribution of dogs across different districts and introduce a Sex perspective into the analysis, the approach has been modified to include a breakdown by Sex. This adjustment allows observation of not only the geographical distribution but also Sex dynamics within the dog population each year.

```{r shiny, total count of dogs by district and dogs Sex, echo=FALSE, message=FALSE, warning=FALSE}

ui <- fluidPage(
    sidebarLayout(
        sidebarPanel(
            selectInput("selectedYear", "Select Year:", 
                        choices = unique(df_EN_EDA$KeyDateYear)),
            selectInput("selectedSex", "Select Sex:",
                        choices = c("All" = "all", "Male" = "male", "Female" = "female")),
            helpText("Displays the total count of dogs by district and sex for the selected year, ordered by total count.")
        ),
        mainPanel(
            plotOutput("dogPlot")
        )
    )
)

server <- function(input, output) {
    output$dogPlot <- renderPlot({
        # Filter data based on the selected year and exclude District 15
        filtered_data <- df_EN_EDA %>%
            filter(KeyDateYear == as.numeric(input$selectedYear), 
                   !is.na(DistrictSort), 
                   DistrictSort != "15")  # Exclude District 15

        # Apply Sex filter if not "All"
        if (input$selectedSex != "all") {
            filtered_data <- filtered_data %>%
                filter(DogSex == input$selectedSex)
        }

        # Aggregate data by district and optionally by Sex
        yearly_data <- filtered_data %>%
            group_by(DistrictSort, DogSex) %>%
            summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
            ungroup() %>%
            arrange(desc(TotalDogs))  # Order by total dogs in descending order

        # Create the bar plot
        p <- ggplot(yearly_data, aes(x = reorder(DistrictSort, -TotalDogs), y = TotalDogs, fill = DogSex)) +
            geom_col(position = position_dodge()) +
            geom_text(aes(label = TotalDogs), vjust = -0.3, color = "black", size = 3.5) +  # Add dog counts on bars
            geom_hline(yintercept = c(100, 500), linetype = "dashed", color = "red") +
            scale_fill_manual(values = c("male" = "salmon", "female" = "darkseagreen")) + 
            scale_y_continuous(limits = c(0, 800), breaks = seq(0, 800, by = 100)) +
            theme_minimal() +
            labs(title = paste("Total Count of Dogs by District and Dog Sex in", input$selectedYear),
                 x = "District",
                 y = "Total Number of Dogs") +
            theme(axis.text.x = element_text(angle = 90, hjust = 1),
                  legend.position = "bottom")

        return(p)
    })
}

shinyApp(ui = ui, server = server)

```

##### 2.2.6.3. By district and Unique owner's sex

This Shiny application provides an interactive visualization of the total count of dogs by district and owner's Sex for a selected year. Users can select a year and the Sex of the owner to explore the distribution of dogs across different districts, facilitating insights into demographic and geographic trends in dog ownership.

```{r shiny, total count of dogs by unique owners Sex, echo=FALSE, message=FALSE, warning=FALSE}

ui <- fluidPage(
    sidebarLayout(
        sidebarPanel(
            selectInput("selectedYear", "Select Year:", choices = unique(df_EN_EDA$KeyDateYear)),
            selectInput("selectedSex", "Select Owner's Sex:", choices = c("Male" = "male", "Female" = "female")),
            helpText("Displays the total count of dogs by district and sex for the selected year.")
        ),
        mainPanel(
            plotOutput("dogPlot")
        )
    )
)

server <- function(input, output) {
    output$dogPlot <- renderPlot({
        # Filter data based on the selected year and exclude District 15
        filtered_data <- df_EN_EDA %>%
            filter(KeyDateYear == as.numeric(input$selectedYear), !is.na(DistrictSort), DistrictSort != "")

        # If 'All' is not selected, further filter by Sex
        if (input$selectedSex != "All") {
            filtered_data <- filtered_data %>%
                filter(OwnerSex == input$selectedSex)
        }

        # Aggregate data by district and optionally by Sex
        aggregated_data <- filtered_data %>%
            group_by(DistrictSort) %>%
            summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
            arrange(desc(TotalDogs))

        # Create the plot using reordered DistrictSort based on TotalDogs
        p <- ggplot(aggregated_data, aes(x = reorder(DistrictSort, -TotalDogs), y = TotalDogs)) +
            geom_col(fill = "darkseagreen") +
            geom_text(aes(label = TotalDogs), vjust = -0.3) +
            geom_hline(yintercept = c(100, 500, 1000, 1500), linetype = "dashed", color = "red") +
            theme_minimal() +
            labs(title = paste("Total Count of Dogs by District in", input$selectedYear,
                               if(input$selectedSex != "All") paste("—", input$selectedSex) else ""),
                 x = "District",
                 y = "Total Number of Dogs") +
            theme(axis.text.x = element_text(angle = 0, hjust = 1),
                  legend.position = "none")  # Optionally remove the legend

        return(p)
    })
}

shinyApp(ui = ui, server = server)

```

##### 2.2.6.4. By district and breed type

To deepen the analysis of dog populations across different districts annually, the R script incorporates an additional layer of granularity by assessing dog counts not only by district but also by breed type. This enhancement provides a more detailed view of the diversity within the canine populations across various districts each year.

```{r shiny, total count of dogs by breedtype, echo=FALSE, message=FALSE, warning=FALSE}

# Define UI
ui <- fluidPage(
    sidebarLayout(
        sidebarPanel(
            selectInput("selectedYear", "Select Year:", choices = unique(df_EN_EDA$KeyDateYear)),
            selectInput("selectedBreedType", "Select Breed Type:", 
                        choices = c("All" = "All", unique(df_EN_EDA$BreedType))),
            checkboxInput("includeUnknown", "Include Unknown Breeds", value = FALSE),
            helpText("Displays the total count of dogs by district and selected breed type for the selected year, excluding District 15.")
        ),
        mainPanel(
            plotOutput("breedPlot")
        )
    )
)

# Define server logic
server <- function(input, output) {
    output$breedPlot <- renderPlot({
        # Filter data based on the selected year and exclude District 15
        filtered_data <- df_EN_EDA %>%
            filter(KeyDateYear == as.numeric(input$selectedYear), DistrictSort != "15", !is.na(DistrictSort))
        
        # Convert DistrictSort to a factor with levels from 1 to 12
        filtered_data$DistrictSort <- factor(filtered_data$DistrictSort, levels = as.character(1:12))

        # Optionally include/exclude unknown breeds based on checkbox input
        if (!input$includeUnknown) {
            filtered_data <- filtered_data %>%
                filter(BreedType != "Unknown")
        }

        # Filter by selected breed type if not 'All'
        if (input$selectedBreedType != "All") {
            filtered_data <- filtered_data %>%
                filter(BreedType == input$selectedBreedType)
        }

        # Aggregate data by district and breed type
        breed_data <- filtered_data %>%
            group_by(DistrictSort, BreedType) %>%
            summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
            arrange(DistrictSort, desc(TotalDogs)) %>%
            group_by(DistrictSort) %>%
            top_n(10, wt = TotalDogs) %>%
            ungroup()

        # Generate the plot
        p <- ggplot(breed_data, aes(x = DistrictSort, y = TotalDogs, fill = BreedType)) +
            geom_col(position = "stack") +
            scale_fill_viridis_d() +
            geom_hline(yintercept = c(100, 500, 1000, 1500), linetype = "dashed", color = "red") +
            scale_y_continuous(limits = c(0, max(1700, max(breed_data$TotalDogs, na.rm = TRUE))), breaks = seq(0, 1700, by = 100)) +
            theme_minimal() +
            labs(title = paste("Top 10 Breed Types by Total Count of Dogs in", input$selectedYear),
                 x = "District",
                 y = "Total Number of Dogs") +
            theme(axis.text.x = element_text(angle = 0, hjust = 1))

        return(p)
    })
}

# Run the application 
shinyApp(ui = ui, server = server)
```

##### 2.2.6.5. By district, breed type and dogs's sex

In an effort to provide a more comprehensive analysis of dog populations within various districts, the latest R script has been enhanced to include not only total counts by district but also a detailed breakdown by breed type and Sex. This enhancement aims to offer a deeper understanding of the diversity and demographics of canine registrations across different regions.

```{r shiny, total count of dogs by breedtype and dogs Sex, echo=FALSE, message = FALSE, warning=FALSE}

# Define UI for the application
ui <- fluidPage(
    sidebarLayout(
        sidebarPanel(
            selectInput("selectedYear", "Select Year:", choices = unique(df_EN_EDA$KeyDateYear)),
            selectInput("selectedBreedType", "Select Breed Type:", choices = c("All", unique(df_EN_EDA$BreedType))),
            selectInput("selectedSex", "Select Sex:", choices = c("All", "Male" = "male", "Female" = "female")),
            checkboxInput("includeUnknown", "Include Unknown Breeds", value = FALSE),
            helpText("Displays the total count of dogs by district, breed type, and Sex for the selected year.")
        ),
        mainPanel(
            plotOutput("dogPlot")
        )
    )
)

# Define server logic
server <- function(input, output) {
    output$dogPlot <- renderPlot({
        # Filter data based on the selected year
        filtered_data <- df_EN_EDA %>%
            filter(KeyDateYear == as.numeric(input$selectedYear), DistrictSort != "15", !is.na(DistrictSort))
        
        # Convert DistrictSort to a factor with levels from 1 to 12
        filtered_data$DistrictSort <- factor(filtered_data$DistrictSort, levels = as.character(1:12))

        # Optionally include/exclude unknown breeds
        if (!input$includeUnknown) {
            filtered_data <- filtered_data %>%
                filter(BreedType != "Unknown")
        }

        # Filter by selected breed type if not 'All'
        if (input$selectedBreedType != "All") {
            filtered_data <- filtered_data %>%
                filter(BreedType == input$selectedBreedType)
        }

        # Filter by selected Sex if not 'All'
        if (input$selectedSex != "All") {
            filtered_data <- filtered_data %>%
                filter(DogSex == input$selectedSex)
        }

        # Calculate total number of dogs per district
        breed_data <- filtered_data %>%
            group_by(DistrictSort, BreedType, DogSex) %>%
            summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
            mutate(Position = as.numeric(DistrictSort) + ifelse(DogSex == "female", -0.2, 0.2))  # Position adjustment for clarity

        # Generate the plot
        p <- ggplot() +
            geom_bar(data = breed_data, aes(x = DistrictSort, y = TotalDogs), fill = "darkseagreen", stat = "identity") +
            geom_point(data = breed_data, aes(x = Position, y = TotalDogs, color = DogSex, shape = BreedType), size = 3, position = position_jitterdodge(jitter.width = 0.1)) +
            geom_hline(yintercept = c(100, 500, 1000, 1500), linetype = "dashed", color = "red") +
            scale_color_manual(values = c("female" = "salmon", "male" = "darkseagreen")) +
            scale_shape_manual(values = seq(1, 20)) +
            scale_y_continuous(limits = c(0, 2000), breaks = seq(0, 2000, by = 500)) +
            theme_minimal() +
            labs(title = paste("Total Count of Dogs by District, Breed, and Sex in", input$selectedYear),
                 subtitle = "Bar: Total Count | Points: Count by Breed and Sex",
                 x = "District",
                 y = "Total Count of Dogs") +
            theme(axis.text.x = element_text(angle = 0, hjust = 1))

        return(p)
    })
}

# Run the application
shinyApp(ui = ui, server = server)

```

---

#### 2.2.7. Top dog breeds

##### 2.2.7.1. Top dog breeds by year

This Shiny application provides a clear and dynamic way to visualize the most popular dog breeds each year, allowing for the inclusion or exclusion of unknown breeds. The color-coding of breeds enhances readability and helps in quickly identifying trends.

```{r shiny, top dog breeds by year, echo=FALSE, message=FALSE, warning=FALSE}

# Function to assign colors to PrimaryBreed
assign_colors <- function(data) {
    n_breeds <- length(unique(data$PrimaryBreed))
    palette <- scales::hue_pal()(n_breeds)
    breed_color_map <- setNames(palette, unique(data$PrimaryBreed))
    return(breed_color_map)
}


ui <- fluidPage(
    sidebarLayout(
        sidebarPanel(
            selectInput("selectedYear", "Select Year:", choices = unique(df_EN_EDA$KeyDateYear)),
            checkboxInput("includeUnknown", "Include Unknown Breeds", value = TRUE),
            helpText("Displays top dog breeds by year")
        ),
        mainPanel(
            plotOutput("breedPlot")
        )
    )
)

server <- function(input, output) {
    output$breedPlot <- renderPlot({
        # Filter data based on the selected year
        filtered_data <- df_EN_EDA %>%
            filter(KeyDateYear == as.numeric(input$selectedYear))

        # Optionally exclude unknown breeds
        if (!input$includeUnknown) {
            filtered_data <- filtered_data %>%
                filter(PrimaryBreed != "Unknown")
        }

        # Aggregate data by PrimaryBreed
        breed_data <- filtered_data %>%
            group_by(PrimaryBreed) %>%
            summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
            arrange(desc(TotalDogs)) %>%
            slice_max(order_by = TotalDogs, n = 10)

        # Check if breed data is empty
        if (nrow(breed_data) == 0) {
            return(ggplot() +
                   labs(title = "No data available for the selected year or criteria",
                        x = "", y = "") +
                   theme_minimal())
        }

        # Assign colors to PrimaryBreed
        breed_color_map <- assign_colors(breed_data)

        # Generate the plot
        p <- ggplot(breed_data, aes(x = reorder(PrimaryBreed, TotalDogs), y = TotalDogs, fill = PrimaryBreed)) +
            geom_col() +
            scale_fill_manual(values = breed_color_map) +
            geom_hline(yintercept = c(250, 500, 750, 1000), linetype = "dashed", color = "red") +
            scale_y_continuous(limits = c(0, max(1250, max(breed_data$TotalDogs, na.rm = TRUE))), breaks = seq(0, max(750, max(breed_data$TotalDogs, na.rm = TRUE)), by = 250)) +
            theme_minimal() +
            labs(title = paste("Top 10 Primary Breeds", input$selectedYear),
                 x = "Primary Breed", y = "Total Number of Dogs") +
            theme(axis.text.x = element_text(angle = 45, hjust = 1))

        return(p)
    })
}

shinyApp(ui = ui, server = server)

```

##### 2.2.7.2. Top dog breeds by district

This visualization enables users to explore the distribution of dog breeds across different districts for a selected year. It highlights the top 5 dog breeds in each district, allowing for a detailed understanding of breed trends and distribution patterns.

```{r shiny, primary breeds by district, echo=FALSE, message=FALSE, warning=FALSE}
  
ui <- fluidPage(
    sidebarLayout(
        sidebarPanel(
            selectInput("selectedYear", "Select Year:", choices = unique(df_EN_EDA$KeyDateYear)),
            checkboxInput("includeUnknown", "Include Unknown Breeds", value = TRUE),
            helpText("Displays top dog breeds by district for the selected year.")
        ),
        mainPanel(
            plotOutput("breedPlot")
        )
    )
)

server <- function(input, output) {
    output$breedPlot <- renderPlot({
        # Filter data based on selected year and exclude District 15
        filtered_data <- df_EN_EDA %>%
            filter(KeyDateYear == as.numeric(input$selectedYear), DistrictSort != "15")

        # Optionally exclude unknown breeds based on checkbox input
        if (!input$includeUnknown) {
            filtered_data <- filtered_data %>%
                filter(PrimaryBreed != "Unknown")
        }

        # Ensure DistrictSort is a factor with levels correctly ordered
        filtered_data$DistrictSort <- factor(filtered_data$DistrictSort, levels = as.character(1:12))

        # Aggregate data
        yearly_data <- filtered_data %>%
            group_by(DistrictSort, PrimaryBreed) %>%
            summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
            arrange(DistrictSort, desc(TotalDogs)) %>%
            group_by(DistrictSort) %>%
            top_n(5, wt = TotalDogs) %>%
            ungroup()

        # Assign colors to PrimaryBreed
        breed_color_map <- assign_colors(yearly_data)

        # Generate the plot
        p <- ggplot(yearly_data, aes(x = DistrictSort, y = TotalDogs, fill = PrimaryBreed)) +
            geom_col(position = "stack") +
            scale_fill_manual(values = breed_color_map) +
            geom_hline(yintercept = c(150, 300, 450, 600), linetype = "dashed", color = "red") +
            scale_y_continuous(limits = c(0, max(600, max(yearly_data$TotalDogs))), breaks = seq(0, max(600, max(yearly_data$TotalDogs)), by = 300)) +
            theme_minimal() +
            labs(title = paste("Top 5 Primary Breeds by Total Count of Dogs in", input$selectedYear),
                 x = "District",
                 y = "Total Number of Dogs") +
            theme(axis.text.x = element_text(angle = 0, hjust = 1))

        return(p)
    })
}

shinyApp(ui = ui, server = server)
```

```{r shiny, all primary breeds by district, echo=FALSE, message = FALSE, warning=FALSE}

# Function to assign colors to PrimaryBreed
assign_colors <- function(data) {
    n_breeds <- length(unique(data$PrimaryBreed))
    palette <- scales::hue_pal()(n_breeds)
    breed_color_map <- setNames(palette, unique(data$PrimaryBreed))
    return(breed_color_map)
}

# Define UI for the application
ui <- fluidPage(
    sidebarLayout(
        sidebarPanel(
            selectInput("selectedYear", "Select Year:", choices = unique(df_EN_EDA$KeyDateYear)),
            selectInput("selectedBreed", "Select Breed Type:", choices = NULL),  # Dynamically populated
            checkboxInput("includeUnknown", "Include Unknown Breeds", value = FALSE),
            helpText("Displays the total count of dogs by district and selected breed type for the selected year.")
        ),
        mainPanel(
            plotOutput("breedPlot")
        )
    )
)

# Define server logic required to draw a plot
server <- function(input, output, session) {
    # Observe the selected year to update breed type options
    observe({
        year_data <- df_EN_EDA %>%
            filter(KeyDateYear == as.numeric(input$selectedYear), !is.na(PrimaryBreed), DistrictSort != "15") %>%
            group_by(PrimaryBreed) %>%
            summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
            arrange(desc(TotalDogs)) %>%
            slice_max(order_by = TotalDogs, n = 10)

        breed_choices <- c("All", year_data$PrimaryBreed)
        updateSelectInput(session, "selectedBreed", choices = breed_choices, selected = breed_choices[1])
    })

    output$breedPlot <- renderPlot({
        # Filter data based on the selected year and exclude District 15
        filtered_data <- df_EN_EDA %>%
            filter(KeyDateYear == as.numeric(input$selectedYear), DistrictSort != "15", !is.na(DistrictSort))

        # Optionally exclude unknown breeds based on checkbox input
        if (!input$includeUnknown) {
            filtered_data <- filtered_data %>%
                filter(PrimaryBreed != "Unknown")
        }

        # If 'All' is not selected for breed type, further filter by selected breed type
        if (input$selectedBreed != "All") {
            filtered_data <- filtered_data %>%
                filter(PrimaryBreed == input$selectedBreed)
        }
        
        # Ensure DistrictSort is a factor with levels correctly ordered
        filtered_data$DistrictSort <- factor(filtered_data$DistrictSort, levels = as.character(1:12))

        # Aggregate data by district and breed type
        aggregated_data <- filtered_data %>%
            group_by(DistrictSort, PrimaryBreed) %>%
            summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
            arrange(DistrictSort, desc(TotalDogs)) %>%
            group_by(DistrictSort) %>%
            top_n(5, wt = TotalDogs) %>%
            ungroup()

        # Assign colors to PrimaryBreed
        breed_color_map <- assign_colors(aggregated_data)

        # Generate the plot
        p <- ggplot(aggregated_data, aes(x = DistrictSort, y = TotalDogs, fill = PrimaryBreed)) +
            geom_col(position = "stack") +
            scale_fill_manual(values = breed_color_map) +
            geom_hline(yintercept = c(100, 250, 500), linetype = "dashed", color = "red") +
            scale_y_continuous(limits = c(0, max(500, max(aggregated_data$TotalDogs))), breaks = seq(0, 500, by = 100)) +
            theme_minimal() +
            labs(title = paste("Top Breeds by Total Count of Dogs in", input$selectedYear),
                 x = "District",
                 y = "Total Number of Dogs") +
            theme(axis.text.x = element_text(angle = 0, hjust = 1))

        return(p)
    })
}

# Run the application 
shinyApp(ui = ui, server = server)

```

```{r shiny, treemap, primary breeds by district, echo=FALSE, message = FALSE, warning=FALSE}

ui <- fluidPage(
    sidebarLayout(
        sidebarPanel(
            selectInput("selectedYear", "Select Year:", choices = unique(df_EN_EDA$KeyDateYear)),
            checkboxInput("includeUnknown", "Include Unknown Breeds", value = TRUE),
            helpText("Displays top dog breeds by district for the selected year.")
        ),
        mainPanel(
            plotOutput("breedPlot")
        )
    )
)

server <- function(input, output) {
    output$breedPlot <- renderPlot({
        # Filter data based on selected year and exclude District 15
        filtered_data <- df_EN_EDA %>%
            filter(KeyDateYear == as.numeric(input$selectedYear), DistrictSort != "15")

        # Optionally exclude unknown breeds based on checkbox input
        if (!input$includeUnknown) {
            filtered_data <- filtered_data %>%
                filter(PrimaryBreed != "Unknown")
        }

        # Aggregate data
        yearly_data <- filtered_data %>%
            group_by(DistrictSort, PrimaryBreed) %>%
            summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
            arrange(DistrictSort, desc(TotalDogs)) %>%
            group_by(DistrictSort) %>%
            top_n(5, wt = TotalDogs) %>%
            ungroup()

        # Plotting the treemap
        treemap(yearly_data,
                index = c("DistrictSort", "PrimaryBreed"),
                vSize = "TotalDogs",
                vColor = "TotalDogs",
                title = paste("Top 5 Primary Breeds by Total Count of Dogs in", input$selectedYear),
                palette = "Spectral")
    })
}

shinyApp(ui = ui, server = server)

```

---

## 3. Machine Learning Models

### 3.1. Linear Model

#### 3.1.1. Linear Model for hypothesis testing: dog age by breed status

For the first chapter in the machine learning models we begin with a linear model that will test the effect of a categorical variable. To do this we set ourselves the following question: _does the breed status have an effect on the age at which dogs are registered?_

Understanding typical registration ages for different breeds will allow Pet Paradise to target marketing effectively, reaching owners at the right stage of their pet ownership journey. Additionally, these insights can inform strategic inventory management, anticipating demand for breed-specific products and offering tailored advice to enhance customer satisfaction.

In the context of the question at hand, it is worth noting that linear models will not be employed to generate predictions from the provided data. Rather, they will be utilized to determine whether there is a linear correlation between the various states of categorical variables (such as pedigree dog, non-pedigree, etc.) and the response variable, which denotes the age of the dog.

```{r linearmodel_01, include=FALSE}

# Clean import of dataset
df_EN <- read.csv("Datasets/df_EN.csv")

# Removing outliers
df_EN_cleaned <- subset(df_EN, DogAgeGroupSort < 100)
# Setting MixedBreed to factor
df_EN_cleaned$MixedBreed <- factor(df_EN_cleaned$MixedBreed)
# Setting reference to pure breeds
df_EN_cleaned$MixedBreed <- relevel(df_EN_cleaned$MixedBreed, 
                                    ref = "Pedigree dog")

```

To answer this question we will consider the `DogAgeGroupSort` as the response variable, and the different levels of the categorical variable `MixedBreed` as predictors. We now direct our attention to the following set of boxplots showcasing the relevant variables.


```{r linearmodel_boxplots, echo=FALSE, fig.width=10, fig.height=8, fig.align='center'}

# Boxplots
boxplots_ggplot <- ggplot(df_EN_cleaned, aes(x = MixedBreed, y = DogAgeGroupSort, fill = MixedBreed)) +
  geom_boxplot() +
  labs(x = "Mixed Breed Status", y = "Dog Registration Age") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplotly(boxplots_ggplot)

```

Based on the boxplots above, there does seem to be a difference in dog ages based on their breed status. Interestingly, the most extreme outliers are associated with pedigree dogs. We will continue by defining a linear model.

```{r linearmodel_lm01, echo=TRUE}

lm.dogs.1 <- lm(DogAgeGroupSort ~ MixedBreed, data = df_EN_cleaned)
summary(lm.dogs.1)

```

The intercept refers to the pure breed dogs, while the following predictors represent the differences between themselves and the intercept. The summary of the linear model suggests there is strong evidence that the mean age of pedigree dogs is not equal to 0 at the time of registration, with a value of 5.7 years, while the other three breed categories' ages differ significantly from that of pedigree dogs. The most noticeable difference is between pedigree dogs and those whose secondary breed is unknown, with the latter being 1.79 years older.

We follow up this insight by assessing the differences between each of them. 

```{r linearmodel_drop1, echo=TRUE}

drop1 <- drop1(lm.dogs.1, test = "F")
drop1

```

```rverbatim
# Single term deletions

Model:
DogAgeGroupSort ~ MixedBreed
           Df Sum of Sq     RSS    AIC F value    Pr(>F)    
<none>                  1216314 201636                      
MixedBreed  3     19384 1235698 202752  376.93 < 2.2e-16 ***
```

By performing single term deletions and evaluating the resulting statistics of the model, we find that the breed status does indeed have a significant effect on the age of dogs across its different levels, however limiting these observation to one level at a time.

We can further this insight by drawing a General Linear Hypothesis. We will consider all possible pairwise comparisons with a *Tukey Honest Significant Difference Test*.

```{r linearmodel_glth, include=FALSE, warning=FALSE, message=FALSE, error=FALSE, echo=FALSE}

if (!require(multcomp, quietly = TRUE)) {
  install.packages("multcomp")
  library(multcomp)
}

glth.test.1 <- glht(model = lm.dogs.1,
                    linfct = mcp(MixedBreed = "Tukey"))
summary(glth.test.1)

```

```{r linearmodel_glth_plot, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, results='hide', fig.align='center', include=TRUE, fig.width=10, fig.height=4, cache=TRUE}

par(mar = c(5, 30, 5, 5) + 0.1)  # c(bottom, left, top, right) + 0.1
plot(glth.test.1,
     main = "Tukey Honest Significant Difference Test",
     sub = "95% family-wise confidence level")

```

In the above _Tukey Honest Significant Difference Test_ the similarity between means of different pairs is shown based on how different they are, with closeness to 0 representing no difference in their means. This, along with the 95% confidence intervals, provides an illustrative insight into pairwise variations.

---

#### 3.1.2. Linear Model: dog count over time

As an additional implementation of linear models, we now aim at answering the following research question: _how do dog counts evolve over time?_ To do so we will build a linear model that will provide some information about the trends in the time series of registered dog count data over the time period recorded, as well as some predictions for the following 10 years.

```{r linearmodel2_count, echo=FALSE, message=FALSE, fig.align='center', fig.width=8, fig.height=6, warning=FALSE}

# Declare the new copied dataframe
df_EN_lm <- df_EN_EDA

# Ensure KeyDateYear is numeric
df_EN_lm$KeyDateYear <- as.numeric(as.character(df_EN_lm$KeyDateYear))

# Aggregate data to get the total dog count per district per year
annual_dog_counts <- df_EN_lm %>%
  filter(!is.na(DistrictSort)) %>%
  group_by(KeyDateYear, DistrictSort) %>%
  summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
  arrange(KeyDateYear, DistrictSort)

# Fit the linear regression model
lm_model <- lm(TotalDogs ~ DistrictSort + KeyDateYear, data = annual_dog_counts)
summary(lm_model)

# Predictions
new_data <- data.frame(
  KeyDateYear = c(2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2030, 2040, 2050),
  DistrictSort = factor(rep(1:12, each = 12))
)

# Predict dog counts
predictions <- predict(lm_model, newdata = new_data)

# Combine observed and predicted data for plotting
combined_data <- merge(annual_dog_counts, data.frame(new_data, predicted_count = predictions), by = c("KeyDateYear", "DistrictSort"), all = TRUE)
head(combined_data)

# Create the line plot
p <- ggplot(combined_data, aes(x = KeyDateYear)) +
  #geom_line(aes(y = TotalDogs, color = DistrictSort, group = DistrictSort), size = 0.5) +  # Observed data
  geom_point(aes(y = TotalDogs, color = DistrictSort), size = 2) +  # Observed data points
  geom_line(aes(y = predicted_count, color = DistrictSort, group = DistrictSort), linetype = "solid", size = 0.5) +  # Predicted data
  scale_x_continuous(breaks = unique(combined_data$KeyDateYear)) +  # Ensure each year is shown on the x-axis
  scale_color_viridis_d(name = "District") +
  theme_minimal() +
  xlim(2015, 2030) + 
  ylim(0, 3000) + 
  labs(title = "LM: Total Count of Dogs by District Over Years with Predictions",
       x = "Year",
       y = "Total Number of Dogs") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "right")

ggplotly(p)

```

The coefficients for each district, represented by the `DistrictSort` variables, show their effect on the total dog count relative to a baseline district. All districts exhibit highly significant effects on dog populations, either positive or negative, with a p-value of less than 0.001. The annual increase in dog counts, indicated by the `KeyDateYear` coefficient of 26.57, reflects a significant positive trend over time, with a p-value of less than 0.001. This consistent annual increase in the dog population underscores the growing trend.

The residuals, i.e. the distribution of prediction errors, go from the smallest value of -132.183 to a maximum of 143.831. The range shows some variability in the model's error terms, yet the overall predictions are reliable. The adjusted R-squared of 98% is very good as it shows that 98% of the data variation is explained by this model.

So the analysis reveals a positive trend over time, suggesting a growing market for dog-related products and services. Pet Paradise can expect to see a sustained and potentially increasing demand for products in their sector.

To make best on the growth in the dog population, strategic recommendations focus on high-growth districts i.e., prioritizing districts with highest positive coefficients such as District 12 (near Schwamendingen Mitte) which has the highest positive coefficient of 1202, indicating the largest growth in dog counts. District 7, known for its expensive neighborhoods around Zürichberg, shows the second highest growth with a coefficient of 974. District 9 also demonstrates substantial growth with a coefficient of 853.

---

### 3.2. Generalized Linear Model (Poisson)

We constructed a Poisson Generalized Linear Model (GLM) to estimate the number of dog registrations (`NumberOfDogs`) based on the predictors `KeyDateYear` and `DistrictCd`. The goal was to identify trends and distributions in dog ownership across Zurich’s neighborhoods to support Pet Paradise's expansion strategy.

```{r poisson_intro, include=TRUE}

first_poisson_model <- glm(NumberOfDogs ~ KeyDateYear + DistrictCd,
                     family = poisson,
                     data = df_EN)

summary(first_poisson_model)

```

```{r poisson_cross_validation, include=FALSE}

set.seed(123)
control <- trainControl(method = "cv", number = 5)

```

``` {r poisson_cross_training, include=FALSE}

if (file.exists("ML1_Final_Dogs_cache/poisson/cv_model.rds")) {
  # Load the model from the .RDS file
  cv_model <- readRDS("ML1_Final_Dogs_cache/poisson/cv_model.rds")
} else {
  # Train the model
  cv_model <- train(NumberOfDogs ~ KeyDateYear + DistrictCd,
                    data = df_EN, method = "glm", family = poisson, trControl = control)
  
  # Save the model as an .RDS file
  saveRDS(cv_model, "ML1_Final_Dogs_cache/poisson/cv_model.rds")
}
```

```{r poisson_summary, include=TRUE}

cv_model

```

We now interpret the results from the Generalized Linear Poisson Model:

- `KeyDateYear`: The coefficient for `KeyDateYear` is -0.0003 with a p-value of 0.832. There's no significant trend over the years in the number of dog registrations. Hence, seasonal trends in dog registrations are not a primary factor for Pet Paradise's planning.

- `DistrictCd`: The coefficient for the neighborhood is -0.0001 with a p-value of 0.927, so no significant difference in dog registrations across different districts. This suggests that district-specific variations in dog registrations might not be substantial.

Specifically in terms of client recommendations, geographical expansion can be addressed. The stable registration numbers mean that given that neither `KeyDateYear` nor `DistrictCd` significantly impact the number of dog registrations, dog ownership seems stable across different years and districts. Therefore, Pet Paradise can consider expanding uniformly across districts rather than focusing on specific areas with presumed higher dog populations.

Therefore in conclusion, this poisson GLM analysis shows a stability in numbers across Zurich. Pet Paradise should leverage this stability and expand based on other factors.

Model Deviance and AIC:

With a null deviance of 191.58 on 70,966 degrees of freedom, the high value indicates considerable variation in the number of dog registrations across the dataset. The residual deviance of 191.53 on 70,964 degrees of freedom how a minimal reduction from the null deviance which means that  the predictors in the model do not significantly improve the fit compared to the null model.

The high AIC value indicates that while the model may have a reasonable fit, it is quite complex relative to the amount of information it provides.
A Fisher Scoring Iterations of four iterations suggests that the model parameters have quickly converged, which we can expect for GLMs with well-behaved data.

Regarding the cross-validation, we used a 5-fold validation, i.e. breaking the data into five subsets, training on four, and testing on the fifth. The low Root Mean Square Error of 0.0593 shows that the model's predictions are close to the actual values of dog registrations.
This R-squared shows that the predictors (here `KeyDateYear` and `DistrictCd`) explain almost none of the variability in the number of dog registrations. This is consistent with the insignificant coefficients observed.

In terms of client insights, the null hypothesis was proven correct in this case; the stability in the number of dog registrations across different years and districts suggests that Pet Paradise can plan for uniform expansion without focusing on specific districts. Other factors such as owner's age, whether they own a pedigree dog or not, etc. might be more influential in determining the demand for pet services, which we will examine in further models.

```{r poisson_predictions, include=FALSE}

# Generate predictions using the fitted model
predictions <- predict(first_poisson_model, type = "response")

```

``` {r poisson_visualization, include=TRUE, fig.align='center', echo=FALSE, fig.keep='all', fig.width=8, fig.height=6}

# Visualize the actual vs predicted number of dogs
ggplot(df_EN, aes(x = NumberOfDogs, y = predictions)) +
  geom_point() +
  labs(title = "Actual vs Predicted Number of Dogs",
       x = "Actual Number of Dogs",
       y = "Predicted Number of Dogs") + 
  theme_minimal()

```

The above visualization helps us see that there is a poor fit; if the model were performing well, it would be a more diagonal spread of points, showing a clear linear relationship between actual and predicted values. The current chart does not show this pattern, so it is suggesting that the model
is not capturing the variability in the actual data. Upon reflection, the model was refined to sum the number of dogs per year, i.e. aggregate it.

```{r poisson_2nd_model, include=FALSE}
# Reiteration of poisson model, now with dogs summed by year for prediction.

# I now sum/aggregate the data by year and district
sum_data <- df_EN %>%
  group_by(KeyDateYear, DistrictCd) %>%
  summarize(NumberOfDogs = sum(NumberOfDogs))

# New fit of  Poisson GLM model
second_poisson_model <- glm(NumberOfDogs ~ KeyDateYear + DistrictCd,
                     family = poisson, data = sum_data)

```

``` {r poisson_2nd_model_sum, include=TRUE, echo=TRUE}

summary(second_poisson_model)

```

```{r poisson_2nd_model_pred, include=FALSE}

predictions <- predict(second_poisson_model, type = "response")
sum_data$PredictedNumberOfDogs = predictions

```

``` {r poisson_2nd_model_vis, include=TRUE, fig.align='center', echo=FALSE, fig.keep='all', fig.width=8, fig.height=6}

p <- ggplot(sum_data, aes(x = NumberOfDogs, y = PredictedNumberOfDogs)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Actual vs Predicted Number of Dog Registrations",
       x = "Actual Number of Dog Registrations",
       y = "Predicted Number of Dog Registrations") +
  theme_minimal()

ggplotly(p)

```

To check which poisson model is better, we compare the goodness-of-fit. This can be done using AIC because the models come from the same dataset, have the same response variable, as well as the same poisson distribution. We also compare coefficients.

```{r poisson_comparisons_1, include=TRUE}

summary_first <- summary(first_poisson_model)
summary_first
summary_first$deviance[1]
summary_first$deviance[2]
summary_first$coefficients

```

```{r poisson_comparisons_2, include=TRUE}
summary_second <- summary(second_poisson_model)
summary_second
summary_second$deviance[1]
summary_second$deviance[2]
summary_second$coefficients

```

There is a big difference between the null deviance (24077) and residual (22173). The degrees of freedom here are lower, so the predictors improved the model's fit. The AIC value (23'067) is lower than the first model's AIC (142'281), meaning a better fit. The coefficients of the second model are statistically significant where p-value < 0.001, and shows an increase of registrations per year (RefYear = 0.044). The negative district coefficient needs to be log transformed to be interpreted since it's a Poisson model.

```rverbatim
exp(District coefficient) = exp(−0.009640) = ca. 0.96
```

The above value is a percentage, so for every one-unit increase in District (ie just one neighborhood to the next), the predicted number of dog registrations approximately decreases by 0.96%.

---

#### 3.2.2. Generalized Linear Model: dog count over time

As a second implementation of Generalized Linear Models, we return to the previously introduced research question: _how do dog counts evolve over time?_

```{r GLM_model - Total Count of Dogs by District Over Years with Predictions, echo=FALSE, message=FALSE, fig.align='center', fig.width=8, fig.height=6, warning=FALSE}

# Declare the new copied dataframe
df_EN_glm <- df_EN_EDA
df_EN_glm$KeyDateYear <- as.numeric(df_EN_glm$KeyDateYear)

# Aggregate data to get the total dog count per district per year
annual_dog_counts <- df_EN_glm %>%
  filter(!is.na(DistrictSort)) %>%
  group_by(KeyDateYear, DistrictSort) %>%
  summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
  arrange(KeyDateYear, DistrictSort)

# Fit the GLM model
glm_model <- glm(TotalDogs ~ KeyDateYear + DistrictSort, data = annual_dog_counts, family = poisson())

# Predictions
new_data <- data.frame(
  KeyDateYear = c(2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2030, 2040, 2050),
  DistrictSort = factor(rep(1:12, each = 12))
)

# Predict dog counts
predictions <- predict(glm_model, newdata = new_data, type = "response")
prediction_data <- data.frame(KeyDateYear = new_data$KeyDateYear, DistrictSort = new_data$DistrictSort, predicted_count = predictions)

# Adjust DistrictSort to have levels from 1 to 12 as indicated
df_EN_glm$DistrictSort <- factor(df_EN_glm$DistrictSort, levels = as.character(1:12))

# Combine observed and predicted data for plotting
combined_data <- merge(annual_dog_counts, prediction_data, by = c("KeyDateYear", "DistrictSort"), all = TRUE)

# Create the line plot
p <- ggplot(combined_data, aes(x = KeyDateYear)) +
  #geom_line(aes(y = TotalDogs, color = DistrictSort, group = DistrictSort), size = 0.5) +  # Observed data
  geom_point(aes(y = TotalDogs, color = DistrictSort), size = 2) +  # Observed data points
  geom_line(aes(y = predicted_count, color = DistrictSort, group = DistrictSort), linetype = "solid", size = 0.5) +  # Predicted data
  scale_x_continuous(breaks = unique(combined_data$KeyDateYear)) +  # Ensure each year is shown on the x-axis
  scale_color_viridis_d(name = "District") +
  theme_minimal() +
  xlim(2015, 2030) + 
  ylim(0, 3000) + 
  labs(title = "GLM: Total Count of Dogs by District Over Years with Predictions",
       x = "Year",
       y = "Total Number of Dogs") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "right")

ggplotly(p)

```

To address the research question _how do dog counts evolve over time?_ we present the following interpretation of the GLM.
    
The coefficient of the yearly growth rate of dog counts is positive, so we have an increasing trend in dog ownership over time, and it is statistically significant. This is especially for District 11 (1202), District 7 (974) and District 9 (853). But only District 15 had a decrease in dogs over the last 10 years (for every 1 year, there were 98 fewer dogs in neighborhood District 15). From the visualization, it’s seen that particularly District 11 had an uptick in dog numbers from 2020, perhaps as people stayed in home office more due to the Covid 19 pandemic.

Regarding the model’s statistics, the model has a strong fit. We see that thanks to the following:

- Residual standard error: 51.28 on 97 degrees of freedom
- Adjusted R-squared: 0.97 % of data variation explain by model
- F-statistic: 407.7 on 13 and 97 DF, p-value: < 2.2e-16, i.e. statistically significant

Pet Paradise can focus on higher growth districts, such as District 11, District 7 and District 9.

---

### 3.3. Generalized Linear Model (Binomial)

We introduction our binomial GLM section by defining the following goal: _predicting a dog's sex based on its age_. In order to work with such models, the response variable must first be transformed to a 0-1 response, as it is originally coded as either 1 for male or 2 for female. Our objective is to assess if there is any significant relationship between dog age and the likelihood of it being either male or female.

```{r glm_bi_libraries, include=FALSE}

if (!require(reshape2, quietly = TRUE))
  {install.packages("reshape2")}
library(reshape2)

if (!require(MASS, quietly = TRUE))
  {install.packages("MASS")}
library(MASS)

if (!require(caret, quietly = TRUE))
  {install.packages("caret")}
library(caret)

if (!require(gplots, quietly = TRUE))
  {install.packages("gplots")}
library(gplots)

```

``` {r glm_bi_preparation, include=FALSE}

# binomials work on binary data only, so dog sex for this dataset must be 0 or 1. i.e. Change from 1 and 2.
df_EN$DogSexCd[df_EN$DogSexCd == 1] <- 0
df_EN$DogSexCd[df_EN$DogSexCd == 2] <- 1

```

``` {r glm_bi_fit1, include=TRUE, echo=TRUE}

glm_dog_sex_age <- glm(DogSexCd ~ DogAgeGroupCd, family = binomial, data = df_EN)
summary(glm_dog_sex_age)

exp_coef <- exp(coef(glm_dog_sex_age))
percentage_change <- (exp_coef - 1) * 100
percentage_change

```

The coefficient for `DogAgeGroupCd` is 0.0035 with a p-value of 0.0104, indicating statistical significance.
For every year increase in dog age, the probability of being female increase by 0.35%, holding other variables constant.
While the statistical significance of the coefficient for a dog's age suggests that there is evidence to support the relationship between dog age and the probability of being female,
the practical significance of a 0.35% increase in odds may not be substantial enough to warrant immediate business decisions based solely on this finding.

Further analysis may be needed here. Although the hypothesis was to offer products tailored to the dog's age and Sex, and while age appears to influence sex likelihood, additional factors such as breed and size would provide a more sound business decision making.

So more investigation into factors would refine predictions. We look at dog breeds. 

``` {r glm_bi_prep, include=FALSE}

# Select my variables. Updated with Owner Age.
df <- df_EN[, c("PrimaryBreed", "DogAgeGroupCd", "DogSexCd", "OwnerAgeGroupCd")]

# clean NAs
missing_values <- colSums(is.na(df))
print(missing_values) # no missing values

summary(df$DogAgeGroupCd)
# output shows max value 999 -> nonsensical. It refers to meaning "age unknown". So we replace it with the average age.
mean_dog_age <- mean(df$DogAgeGroupCd[df$DogAgeGroupCd != 999], na.rm = TRUE)
df <- df %>%
  mutate(DogAgeGroupCd = ifelse(DogAgeGroupCd == 999, mean_dog_age, DogAgeGroupCd))
summary(df$DogAgeGroupCd) # now output makes much more sense.
#  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
#0.000   2.000   5.000   5.887   9.000  23.000

# Distributions
table(df$DogSexCd)
# The distribution of dog sexes shows there are 35,409 female dogs (coded 0) and 35,558 male dogs (coded 1).
# There's no significant skew towards one sex in the dataset.

# Favourite 5 breeds
breed_counts <- table(df$PrimaryBreed)
sorted_breeds <- sort(breed_counts, decreasing = TRUE)
top_5_breeds <- head(sorted_breeds, 5)
top_5_breeds

```


| Breed              | Unknown   | Chihuahua | Labrador Retriever  | Yorkshire Terrier | Jack Russel Terrier |
|--------------------|-----------|-----------|---------------------|-------------------|---------------------|
| Count              | 9095      | 4828      | 4198                | 2709              | 2579                |


The most popular dog is a unknown ie. mixed dog breed. So Pet Paradise must offer mixed breed foods and products. Not only purebred product offerings.

So instead, another sales approach. Let us say, Pet Paradise is trying to target specific dog or owner age groups for marketing or sales purposes. Pet Paradise wants to predict the likelihood of a pet owner in their 40s owning a top 5 breed (e.g., the Chihuahua) compared to owning an unknown breed. For this, a binomial logistic regression makes most sense to use. This is because the response variable is binary: either a pet owner owns a Chihuahua (let say, coded as 1) or they own an unknown breed (we will code this as 0).

In terms of identifying popular breeds based on age and sex, Pet Paradise wants to use a model's predictions to optimize inventory management by stocking up on products that are likely to be in higher demand based on the popularity of a given pedigree breed.

``` {r glm_bi_prep2, include=FALSE}

# Now that the top 5 breeds are identified, a new subset should be created for owners in their 40s and for the top 5 breeds
owner_40s_df <- df[df$OwnerAgeGroupCd == 40 & df$PrimaryBreed %in% names(top_5_breeds), ]

# Create a binary variable for Chihuahua ownership
owner_40s_df$ChihuahuaOwned <- ifelse(owner_40s_df$PrimaryBreed == "Chihuahua", 1, 0)

# Check if there are any 0s in the ChihuahuaOwned column
head(owner_40s_df)
any(owner_40s_df$ChihuahuaOwned == 0)  # Yes, we get TRUE because there are other breeds

# Check if there are any 0s in the ChihuahuaOwned column
any(owner_40s_df$ChihuahuaOwned == 0)  # Should be TRUE if there are other breeds

```


``` {r glm_bi_fit2, include=TRUE, echo=TRUE}

chihuahua_binomial <- glm(ChihuahuaOwned ~ 1, family = binomial, data = owner_40s_df)
summary(chihuahua_binomial)

```


``` {r glm_bi_fit2_odds, include=TRUE, echo=TRUE}

chihuahua_exp_coef <- exp(coef(chihuahua_binomial))
chihuahua_exp_coef
chihuahua_percentage_change <- (chihuahua_exp_coef - 1) * 100
chihuahua_percentage_change

```

We see that the log-odds of a 40-year-old owning a Chihuahua are -1.29, which is statistically significant. The exponentiated coefficient is 0.27, indicating that the odds of a 40-year-old owning a Chihuahua are 27%. If Pet Paradise targets typically well-earning professionals, i.e., adults in their 40s, and since the likelihood of a dog owner in their 40s owning a Chihuahua is relatively low, Pet Paradise diversify marketing efforts away from pedigree focus and rather highlight a broader range of mixed-breed foods, fur-shampoos and other products. This strategy will help attract well-earning customers who may own mixed or different breeds.

To check a last potential business case, we can check the reverse; predict which owner age group is more likely to own a Chihuahua, because we have a binary variable (`ChihuahuaOwned`: 1 for ownership and 0 for no ownership) and the remaining predictor variables (`PrimaryBreed`, `DogAgeGroupCd`, `DogSexCd`, and `OwnerAgeGroupCd`). We will try o predict which owner age group is more likely to own a Chihuahua.

```rverboatim
chihuahua_age_bracket <- glm(formula = ChihuahuaOwned ~ PrimaryBreed + DogAgeGroupCd + DogSexCd + OwnerAgeGroupCd, family = binomial, data = owner_40s_df)
summary(chihuahua_age_bracket)

# Collinearity because model didn't converge. We calculate variance inflation factors
vif_values <- car::vif(chihuahua_age_bracket)
vif_values
```

The VIF produced by the above code shows that the model has perfect multicollinearity. It creates in linear dependencies among predictor variables. What this means, is that when there are categorical variables with many levels, it leads to unreliable predictions. So, if Pet Paradise is trying to predict which customers want to buy a product based on their age braket, breed of dog, etc, such a model with these singularities might suggest targeting certain groups of customers when, in fact, the data is too ambiguous to make such recommendations confidently We will compare the first two of the three models to determine the better fit instead.

``` {r glm_bi_comp1, include=FALSE}

# AIC and BIC for Model 1: Dog Sex vs. Age
aic_model1 <- AIC(glm_dog_sex_age)
bic_model1 <- BIC(glm_dog_sex_age)

# AIC and BIC for Model 2: Chihuahua Ownership in 40s
aic_model2 <- AIC(chihuahua_binomial)
bic_model2 <- BIC(chihuahua_binomial)

```

``` {r glm_bi_comp2, include=TRUE, echo=TRUE}

cat("Model 1 - Dog Sex vs. Age:\n")
cat("AIC:", aic_model1, "\n")
cat("BIC:", bic_model1, "\n\n")

cat("Model 2 - Chihuahua Ownership in 40s:\n")
cat("AIC:", aic_model2, "\n")
cat("BIC:", bic_model2, "\n")

```

We see from the Akaike Information Criterion and Bayesian Information Criterion that the second model, i.e. Chihuahua Ownership in an owner's 40s, has much lower AIC and BIC values than the Dog Sex vs. Age model. So model 2 provides a better fit to the data. Because the models contain fewer than 2 terms, checking collinearity doesn't make sense. We check the confusion matrices instead.

``` {r glm_bi_comp3, include=TRUE, fig.align='center', echo=TRUE, fig.keep='all', fig.width=8, fig.height=6}

# Confusion matrix for Dog Sex vs. Age
predicted_probabilities <- predict(glm_dog_sex_age, type = "response")
predicted_classes <- ifelse(predicted_probabilities > 0.5, 1, 0)
confusion_glm1 <- table(df_EN$DogSexCd, predicted_classes)
confusion_glm1

```

``` {r glm_bi_comp4, include=FALSE}

# 1. Confusion matrix values
TN <- 15813
FP <- 19596
FN <- 14672
TP <- 20886

# accuracy and precision
accuracy <- ((TP + TN) / (TP + TN + FP + FN)) * 100
precision <- (TP / (TP + FP)) * 100

# sensitivity
recall <- (TP / (TP + FN)) * 100

```

The first confusion matrix shows that there are correctly predicted the negatives was 15,813 instances. The false positive representing incorrectly predicted the positive cases was 19,596 false positives. There were 14,672 false negative predictions and 20,886 true positives. This means the first binomial model has an accuracy of 52% and a precision of 52%. The Sensitivity was around 59%, where of all actual positive instances were correctly identified by the model.

The client question of this analysis was to develop and compare binomial logistic regression models to predict outcomes regarding dog ownership based on given variables. We examined on two main models: one predicting the sex of the dog based on its age group and another predicting the most popular pedigree ownership among dog owners in their prime income earning years in their 40s.

The first model offered insights into the relationship between dog age and sex but had limited predictive power. The second model provided a baseline probability of pedigree ownership based on created binary variables of ownership vs non-ownership to target a very specific demographic niche. While attempting to include multiple predictors in the third pedigree ownership model, perfect multicollinearity was detected, resulting in unstable estimates and difficulties in model convergence. For Pet Paradise, focusing on targeting broader product ranges to well-earning professionals, rather than narrowly focusing on pedigree breeds, could be more effective.

---

### 3.4. Generalized Additive Model

```{r gam_libraries, include=FALSE}

if (!require(mgcv, quietly = TRUE)) {install.packages("mgcv")}
library(mgcv)

if (!require(effects, quietly = TRUE)) {install.packages("effects")}
library(effects)

```

#### 3.4.1. GAM model: evolution of popular breeds

To assess Pet Paradise on the question of _evolution of popular dog breeds_ we will employ Generalized Additive Models (GAM). Such models can capture the non-linear patterns inherent in the popularity fluctuations of various dog breeds throughout the years. This analysis will enable Pet Paradise to make informed predictions about future trends, thereby facilitating their ability to anticipate the demand for breed-specific products.

First we have a look at all districts together.

```{r GAM for 5 Top breed  - ALL DISTRICTS TOGETHER, echo=FALSE, message=FALSE, fig.align='center', fig.width=8, fig.height=6, warning=FALSE}

# Clean reload of data
df_EN_gam <- read.csv('Datasets/df_EN_EDA.csv')

# Ensure correct type
df_EN_gam$KeyDateYear <- as.numeric(as.character(df_EN_gam$KeyDateYear))
df_EN_gam$PrimaryBreed <- factor(df_EN_gam$PrimaryBreed)

# Aggregating data to get count of dogs per breed per year (ignoring district)
breed_trends <- df_EN_gam %>%
  group_by(KeyDateYear, PrimaryBreed) %>%
  summarise(BreedCount = sum(NumberOfDogs), .groups = 'drop') %>%
  filter(PrimaryBreed != "Unknown" & PrimaryBreed %in% c("Chihuahua", "Labrador Retriever", "Yorkshire Terrier", "Jack Russel Terrier", "Malteser")) %>%
  as.data.frame()

# Ensure no NA values in the key variables
breed_trends <- breed_trends %>%
  filter(!is.na(BreedCount), !is.na(KeyDateYear))

# R-sq.(adj) =  0.994   Deviance explained = 99.6%
gam_model <- gam(BreedCount ~ te(KeyDateYear, by = PrimaryBreed, k = 8) + s(PrimaryBreed, bs = "re"),
                 data = breed_trends, method = "REML", family = poisson(link = "log"))

# Prepare new data for prediction
new_data <- data.frame(
  KeyDateYear = rep(seq(2015, 2030, by = 1), times = 5),
  PrimaryBreed = factor(rep(c("Chihuahua", "Labrador Retriever", "Yorkshire Terrier", "Jack Russel Terrier", "Malteser"), each = 16),
                        levels = c("Chihuahua", "Labrador Retriever", "Yorkshire Terrier", "Jack Russel Terrier", "Malteser"))
)

# Predict counts for the new dataset
new_data$predicted_breed_count <- predict(gam_model, newdata = new_data, type = "response")

# Function to assign colors to breeds
assign_colors <- function(data) {
  breeds <- unique(data$PrimaryBreed)
  colors <- scales::hue_pal()(length(breeds))
  setNames(colors, breeds)
}
breed_color_map <- assign_colors(new_data)

gg <- ggplot() +
  geom_line(data = new_data, aes(x = KeyDateYear, y = predicted_breed_count, color = PrimaryBreed), size = 1) +
  geom_point(data = breed_trends, aes(x = KeyDateYear, y = BreedCount, color = PrimaryBreed), size = 2) +
  # ylim(0, 600) +
  labs(x = "Year", y = "Count", title = "Yearly Trend of Predicted and Actual Breed Counts (Summed across all Districts)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top") +
  guides(color = guide_legend(title = "Breed", title.position = "top"))

ggplotly(gg)

# Summary and diagnostic plots of the combined model
summary(gam_model)

```

The GAM visualization displays the evolving popularity of various dog breeds over time and makes the non-linear patterns in the breed popularity fluctuations obvious across time. The model, constructed with a Poisson family and a log link function, aims to predict breed counts by incorporating a tensor product smooth term for time (`KeyDateYear`) and breed (`PrimaryBreed`), along with a smooth term for breed alone. The coefficients derived from the model highlight significant associations between time and the popularity of specific breeds, i.e., breeds like Labradors and Maltesers show noticeable patterns in popularity over time, as indicated by their significant smooth terms. Finally, the model's high adjusted R-squared value highlight its good fit in explaining the data variability.

Next we direct our attention to each individual city district.

```{r GAM for 5 Top breed  - Per DISTRICT,  echo=FALSE, message=FALSE, fig.align='center', fig.width=8, fig.height=6, warning=FALSE}

# Ensure correct type
df_EN_gam$KeyDateYear <- as.numeric(as.character(df_EN_gam$KeyDateYear))
df_EN_gam$PrimaryBreed <- factor(df_EN_gam$PrimaryBreed)
df_EN_gam$DistrictSort <- factor(df_EN_gam$DistrictSort, levels = 1:12)

# Aggregating data to get count of dogs per breed per year per district
breed_trends <- df_EN_gam %>%
  group_by(KeyDateYear, PrimaryBreed, DistrictSort) %>%
  summarise(BreedCount = sum(NumberOfDogs), .groups = 'drop') %>%
  filter(PrimaryBreed != "Unknown" & 
           PrimaryBreed %in% c("Chihuahua", "Labrador Retriever", "Yorkshire Terrier", "Jack Russel Terrier", "Malteser")) %>%
  as.data.frame()

# Check the structure of the aggregated data
str(breed_trends)

# Ensure no NA values in the key variables
breed_trends <- breed_trends %>%
  filter(!is.na(BreedCount), !is.na(KeyDateYear), !is.na(DistrictSort))

# Prepare new data for prediction for each district
new_data <- expand.grid(
  KeyDateYear = seq(2015, 2030, by = 1),
  PrimaryBreed = factor(c("Chihuahua", "Labrador Retriever", "Yorkshire Terrier", "Jack Russel Terrier", "Malteser"),
                        levels = c("Chihuahua", "Labrador Retriever", "Yorkshire Terrier", "Jack Russel Terrier", "Malteser")),
  DistrictSort = factor(1:12, levels = 1:12)
)

# Function to fit the GAM model and make predictions for a specific district
fit_gam_and_predict <- function(district) {
  district_data <- breed_trends %>% filter(DistrictSort == district)
  
  # Check if there are enough data points to fit the model
  if(nrow(district_data) < 10) {
    return(NULL)  # Skip this district if not enough data
  }
  
  # Fit the GAM model with reduced complexity and interaction terms
  gam_model <- gam(BreedCount ~ s(KeyDateYear, bs = "cr", k = 5) + s(PrimaryBreed, bs = "re"),
                   data = district_data, method = "REML", family = poisson(link = "log"))
  
  # Predict counts for the new dataset
  new_data_district <- new_data %>% filter(DistrictSort == district)
  new_data_district$predicted_breed_count <- predict(gam_model, newdata = new_data_district, type = "response")
  
  return(new_data_district)
}

# Apply the function to each district and combine the results
predicted_data_list <- lapply(levels(df_EN_gam$DistrictSort), fit_gam_and_predict)
predicted_data <- do.call(rbind, predicted_data_list[!sapply(predicted_data_list, is.null)])

# Function to assign colors to breeds
assign_colors <- function(data) {
  breeds <- unique(data$PrimaryBreed)
  colors <- scales::hue_pal()(length(breeds))
  setNames(colors, breeds)
}
breed_color_map <- assign_colors(new_data)

gg <- ggplot() +
  geom_line(data = predicted_data, aes(x = KeyDateYear, y = predicted_breed_count, color = PrimaryBreed), size = 1) +
  geom_point(data = breed_trends, aes(x = KeyDateYear, y = BreedCount, color = PrimaryBreed), size = 1) +
  facet_wrap(~DistrictSort, scales = "free_y") +
  ylim(0, 200) +
  labs(x = "Year", y = "Count", title = "Yearly Trend of Predicted and Actual Breed Counts per District") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top") +
  guides(color = guide_legend(title = "Breed", title.position = "top"))

ggplotly(gg)

# Check the summary and diagnostic plots for one of the models (optional)
district_example <- levels(df_EN_gam$DistrictSort)[1]
example_model <- gam(BreedCount ~ s(KeyDateYear, bs = "cr", k = 5) + s(PrimaryBreed, bs = "re"),
                     data = breed_trends %>% filter(DistrictSort == district_example), method = "REML", family = poisson(link = "log"))
summary(example_model)

```

From the summary, we see that the dataset comprises 540 observations across 12 district levels, tracking variables such as the year and primary dog breed the district and breed count. So this GAM also uses a smooth term for time thanks to a cubic regression spline but with a complexity parameter (k) set to 5, alongside a smooth term for the primary dog breed. The smooth terms show significant relationships between the specific dog breed popularity and time, and interestingly enough also between breeds and districts. While the time significance is marginal, the breed component shows a substantial effect on breed popularity across districts. We can observe how the model's adjusted R-squared value explain slightly less data variability at 82%, but it is still a good fit. We recommend for our client, Pet Paradise, that this local analysis presents into district-specific trends in dog breed popularity; they can target breeds like the Labrador and Chihuahua in particular, with marketing tailored to those dogs’ needs.

---

#### 3.4.2. GAM model: dog count over time

For the second part of the Generalized Additive Model chapter we again direct our attention to the previously posed research question: _how do dog counts evolve over time?_

As a straightforward implementation of the GAM model, we set ourselves to produce a regression of the registered count data, grouped by districts of the city, analyze their evolution over time, and additionally provide predictions for the next 10 years.

```{r gam_model_simple - Total Count of Dogs by District Over Years with Predictions, echo=FALSE, message=FALSE, fig.align='center', fig.width=8, fig.height=6, warning=FALSE}

df_EN_gam <- df_EN_EDA

# Aggregate data to get the total dog count per district per year
annual_dog_counts <- df_EN_gam %>%
  filter(!is.na(DistrictSort)) %>%
  group_by(KeyDateYear, DistrictSort) %>%
  summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
  arrange(KeyDateYear, DistrictSort)

# Fit the GAM model with reduced knots
gam_model_simple <- gam(TotalDogs ~ s(KeyDateYear, bs = "cr", k = 4) + s(DistrictSort, bs = "re"),
                        data = annual_dog_counts, method = "REML", family = poisson(link = "log"))
summary(gam_model_simple)

# Predictions
new_data <- data.frame(
  KeyDateYear = c(2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2030, 2040, 2050),
  DistrictSort = factor(rep(1:12, each = 12))
)

# Predict dog counts
predictions <- predict(gam_model_simple, newdata = new_data, type = "response")
prediction_data <- data.frame(KeyDateYear = new_data$KeyDateYear, DistrictSort = new_data$DistrictSort, predicted_count = predictions)

# Adjust DistrictSort to have levels from 1 to 12 as indicated
df_EN_gam$DistrictSort <- factor(df_EN_gam$DistrictSort, levels = as.character(1:12))

# Combine observed and predicted data for plotting
combined_data <- merge(annual_dog_counts, prediction_data, by = c("KeyDateYear", "DistrictSort"), all = TRUE)
head(combined_data)

# Create the line plot
p <- ggplot(combined_data, aes(x = KeyDateYear)) +
  #geom_line(aes(y = TotalDogs, color = DistrictSort, group = DistrictSort), size = 0.5) +  # Observed data
  geom_point(aes(y = TotalDogs, color = DistrictSort), size = 2) +  # Observed data points
  geom_line(aes(y = predicted_count, color = DistrictSort, group = DistrictSort), linetype = "solid", size = 0.5) +  # Predicted data
  scale_x_continuous(breaks = unique(combined_data$KeyDateYear)) +  # Ensure each year is shown on the x-axis
  scale_color_viridis_d(name = "District") +
  theme_minimal() +
  xlim(2015, 2030) + 
  ylim(0, 3000) + 
  labs(title = "GAM: Total Count of Dogs by District Over Years with Predictions",
       x = "Year",
       y = "Total Number of Dogs") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "right")

ggplotly(p)

```

We now proceed to further omptimize the GAM model. The smooth term complexity parameter is now k = 8 and we see that it allows for a more detailed, fitted representation of change over time. Despite the adjusted R-squared value dropping by 0.01% from 99.7% to 99.6%, the model shows a high level of significance for both smooth terms, explaining a large portion of the data variability.

```{r gam_model_refined - Total Count of Dogs by District Over Years with Predictions, echo=FALSE, message=FALSE, fig.align='center', fig.width=8, fig.height=6, warning=FALSE}

# Create a subset of the data where DistrictSort is a factor
df_subset <- df_EN_gam %>%
  filter(!is.na(DistrictSort)) %>%
  mutate(DistrictSort = factor(DistrictSort, levels = as.character(1:12)))

# Aggregate data to get the total dog count per district per year
annual_dog_counts <- df_subset %>%
  group_by(KeyDateYear, DistrictSort) %>%
  summarize(TotalDogs = sum(NumberOfDogs), .groups = 'drop') %>%
  arrange(KeyDateYear, DistrictSort)

# Fit the simplified GAM model
gam_model_refined <- gam(TotalDogs ~ s(KeyDateYear, bs = "cr", k = 8) +
                         s(DistrictSort, bs = "re"),
                         data = annual_dog_counts, method = "REML", family = poisson(link = "log"))
summary(gam_model_refined)

# Predictions
new_data <- data.frame(
  KeyDateYear = rep(c(2015:2023, 2030, 2040, 2050), each = 12),
  DistrictSort = factor(rep(1:12, times = 12), levels = as.character(1:12))
)

# Predict dog counts
predictions <- predict(gam_model_refined, newdata = new_data, type = "response")
prediction_data <- data.frame(KeyDateYear = new_data$KeyDateYear, DistrictSort = new_data$DistrictSort, predicted_count = predictions)

# Combine observed and predicted data for plotting
combined_data <- merge(annual_dog_counts, prediction_data, by = c("KeyDateYear", "DistrictSort"), all = TRUE)

# Create the line plot
p <- ggplot(combined_data, aes(x = KeyDateYear)) +
  geom_point(aes(y = TotalDogs, color = DistrictSort), size = 2) +  # Observed data points
  geom_line(aes(y = predicted_count, color = DistrictSort, group = DistrictSort), linetype = "solid", size = 0.5) +  # Predicted data
  scale_x_continuous(breaks = unique(combined_data$KeyDateYear)) +  # Ensure each year is shown on the x-axis
  scale_color_viridis_d(name = "District") +
  theme_minimal() +
  xlim(2015, 2030) + 
  ylim(0, 3000) + 
  labs(title = "GAM refined: Total Count of Dogs by District Over Years with Predictions",
       x = "Year",
       y = "Total Number of Dogs") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "right")

ggplotly(p)

```

This GAM model also uses a Poisson distribution with a log link function, but the a smooth term for time has a complexity parameter (k) set to 4, and another smooth term for the district (`DistrictSort`). Again, there are positive correlations between dog counts and both time and district, as seen in the visualization. What we see is the noticeable impact of time and district on the increase in dog populations. Our recommendation to the client is that for the next 10 years, Pet Paradise can expect positive dog population growth trends as a forecast, and expand their business accordingly to meet the dog owners demands and needs in each district.

---

#### 3.4.3. Model comparison

We now look at some comparisons now between the above two models, as well as the GLM that was introduced earlier. 

```{r gam_comparisons, fig.align='center', echo=FALSE, message=FALSE, warning=FALSE}

# Create data frames for each model's fitted values and residuals
df_gam_simple <- data.frame(
  fitted_values = gam_model_simple$fitted.values,
  residuals = resid(gam_model_simple),
  model = "Simple GAM"
)

df_gam_refined <- data.frame(
  fitted_values = gam_model_refined$fitted.values,
  residuals = resid(gam_model_refined),
  model = "Refined GAM"
)

df_glm <- data.frame(
  fitted_values = glm_model$fitted.values,
  residuals = resid(glm_model),
  model = "GLM"
)

# Combine the data frames
combined_data <- rbind(df_gam_simple, df_gam_refined, df_glm)

# Create the ggplot object
p <- ggplot(combined_data, aes(x = fitted_values, y = residuals, color = model)) +
  geom_point() +
  labs(
    title = "GAM Comparison: Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  scale_color_manual(values = c("GLM" = "darksalmon", "Simple GAM" = "darkturquoise", "Refined GAM" = "goldenrod")) +
  theme_minimal() +
  theme(legend.position = "top")

# Convert the ggplot object to a Plotly object
ggplotly(p)

```

The residuals versus fitted values scatterplot appears without patter, indicating that the models have caught most of the data variation, although the GLM does have the most outliers. The simple GLM appears to have the least outliers. The visualization shows homoscedasticity, ie a consistent spread, which is good. All models are satisfactory for this business question.

```{r gam_comparisons_2, include=FALSE}

# Extract and plot the effect of time for a few districts
library(effects)
for(district in unique(combined_data$prediction_count)[1:12]) {
  effect_data <- effect("KeyDateYear", gam_model_refined, xlevels = list(DistrictSort = district))
  effect_df <- as.data.frame(effect_data)

  ggplot(effect_df, aes(x = KeyDateYear, y = fit)) +
    geom_line(shade = TRUE, size = 1) +
    geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
    labs(title = paste("Effect of Year in District", district),
         x = "Year", y = "Fitted TotalDogs Count") +
    theme_minimal()
}

```

```{r gam_comparisons_AIC, echo=TRUE, include=TRUE}

aic_comparison <- AIC(gam_model_simple, gam_model_refined)
aic_comparison

```
```rverbatim
> aic_comparison
                        df      AIC
gam_model_simple  15.88798 999.1300
gam_model_refined 16.88099 987.7553
```

The lower AIC value from the refined version of the GAM model shows the improvement of its accuracy.

---

### 3.5. Artificial Neural Network

We start this chapter by posing the research question: _is a dog of pure or mixed breed, based on location and owner and dog’s characteristics?_

An artificial neural network (ANN) is the algorithm of choice for this assessment due to its capability to handle complex, non-linear relationships within the dataset. Dogs' breed may depend on various interacting factors, such as age, size, location, and owner demographics, which ANNs can effectively capture and analyze. 

Their scalability and adaptability make them robust for ongoing studies, while their multilayered learning allows the model to automatically identify the most significant features. We ultimately aim to accurately predict breed status and provide valuable insights for our suggested business project, as well as pet adoption agencies, veterinarians, or even urban planners of the city of Zurich.

Continuing with the development of models, and answering the above, we now look into the implementation of an Artificial Neural Network using the packages `nnet` and `caret` in R. The resulting classification result for the dependent variable will be produced by the model considering variables of both numerical and categorical type.

The target variable `MixedBreed` is of categorical type (factor in R), indicating the dog’s pedigree status, with 4 different possible responses, from pure breed to 3 different descriptors of breed mixing. For the sake of simplicity, the levels within the `MixedBreed` factor variable have been reduced to a binary response, indicating whether the dog is of pure pedigree or not. We consider that this response better fits the information needed for our business case. 

As explained above, the response variables of choice pertain to characteristics of the dog owners (their age, sex, and district), as well as some characteristics of the dogs (dog age and sex). The predictors are the following: `OwnerAgeGroupCd`, `OwnerSexCd`, `DistrictCd`, `DogAgeGroupCd` and `DogSexCd`. Although the model results suggest that incorporating additional predictors should be done to improve the model's accuracy, we have kept the current selection for learning purposes.

The libraries of choice are `nnet` and `caret`, the first one providing the functions for creating and training the model, and the latter providing an interface to further preprocess and train the model. This allowed to implement a 10-fold cross-validation during the training phase of the model building. It also allowed to establish a tune grid with various possible hyperparameters to test out different combinations and find the most optimal ones.

``` {r neuralnetwork_libraries, include=FALSE}

# Install dependencies

# For the ANNs
if (!require(nnet, quietly = TRUE)) {
  install.packages("nnet")
  library(nnet)
}
# For model training and evaluation
if (!require(caret, quietly = TRUE)) {
  install.packages("caret")
  library(caret)
}
# For the visualization
if (!require(gamlss.add, quietly = TRUE)) {
  install.packages("gamlss.add")
  library(gamlss.add)
}
# For the quality assessment
if (!require(ROCR, quietly = TRUE)) {
  install.packages("ROCR")
  library(ROCR)
}

```

```{r neuralnetwork_sampling, include=FALSE}

# Select a subset of variables of interest
variables_net <- c("OwnerAgeGroupCd",
                "OwnerSex", 
                "District",
                "DogAgeGroupCd",
                "DogSex", 
                "MixedBreed")
df_net <- df_EN[variables_net]

#### PREPARATION OF DATA: FACTORS AND SAMPLING ####

# Convert categorical variables to factors
df_net$OwnerAgeGroupCd <- as.integer(df_EN$OwnerAgeGroupCd)  # Keep as numerical
df_net$OwnerSex <- as.factor(df_EN$OwnerSex)
df_net$District <- as.factor(df_EN$District)
df_net$DogAgeGroupCd <- as.integer(df_EN$DogAgeGroupCd)      # Keep as numerical
df_net$DogSex <- as.factor(df_EN$DogSex)
df_net$MixedBreed <- as.factor(df_EN$MixedBreed)             # Response variable

# Creating a new binary target variable from multinomial
# Pedigree dog stays as such, all others are mixed breeds, and set to factor
df_net$BinaryMixedBreed <- ifelse(df_net$MixedBreed == "Pedigree dog",
                                 "Pedigree dog",
                                 "Mixed breed")
df_net$BinaryMixedBreed <- as.factor(df_net$BinaryMixedBreed)
df_net <- df_net[, -which(names(df_net) == "MixedBreed")] # Remove original var.

# Split the data into training and testing sets
# The split is done proportionally for the BinaryMixedBreed variable
set.seed(123)  # for reproducibility
trainIndex <- createDataPartition(df_net$BinaryMixedBreed,
                                  p = 0.8, 
                                  list = FALSE,
                                  times = 1)
df_train <- df_net[trainIndex, ]
df_test <- df_net[-trainIndex, ]

```

``` {r neuralnetwork_train, include=FALSE}

# Cache save location
model_path <- "ML1_Final_Dogs_cache/nnet/breed_net.rds"

if (file.exists(model_path)) {
  # Load the cached model
  breed_net <- readRDS(model_path)
} else {
  
  # Define the control function for training
  train_control <- trainControl(method = "cv", number = 10)
  
  # Hyperparameters
  grid <- expand.grid(size = c(5, 10, 15), decay = c(0.01, 0.001, 0.0001))
  
  set.seed(123)
  # Train neural network model with selected features, hyperparameter tuning
  breed_net <- train(BinaryMixedBreed ~ .,
                      data = df_train,
                      method = "nnet",
                      trControl = train_control,
                      tuneGrid = grid,
                      linout = FALSE,           # For categorical response
                      trace = TRUE,             # To see what's happening live
                      maxit = 10000)            # Max. number of iterations

  # Save the model to disk to ensure it is not re-trained
  saveRDS(breed_net, model_path)
  
}

```

```{r neuralnetwork_print, include=TRUE}

breed_net
breed_net$finalModel

```

```{r neuralnetwork_predict, include=FALSE}

# Make predictions on the test set
predictions_binary <- predict(breed_net, newdata = df_test)
predictions_binary <- factor(predictions_binary)  # Is this necessary?
df_test$BinaryMixedBreed <- factor(df_test$BinaryMixedBreed)

# Generate the confusion matrix
cm_binary <- confusionMatrix(predictions_binary, df_test$BinaryMixedBreed)
cm_binary

# Convert the confusion matrix to a data frame
cm_binary_df <- as.data.frame(cm_binary$table)

# Rename the columns for better readability
colnames(cm_binary_df) <- c("Prediction", "Reference", "Freq")

```

``` {r neuralnetwork_plot, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, results='hide', fig.keep='all', fig.align='center'}

#### PLOTTING THE MODEL ####

# Extract the final model
final_model <- breed_net$finalModel
# Plot the neural network
plot(final_model)

```

After running the code, the final model is a neural network with 16 input nodes, 15 hidden nodes, and 1 output node, totalling 271 weights. However, an evaluation of the confusion matrix and ROC curves indicates insufficient evidence to support the model's validity for the given variables. This issue might stem from the selection of variables; expanding the set to include more variables from the dataset might improve the model. Alternatively, it could be that an artificial neural network is not the most suitable model for addressing this particular research question.

```{r neuralnetwork_conf_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}

# Confusion matrix plot
net_ggplot <- ggplot(data = cm_binary_df, aes(x = Reference, y = Prediction, fill = Freq)) +
    geom_tile() +
    scale_fill_gradient(low = "darkseagreen1", high = "springgreen4") +
    geom_text(aes(label = Freq), vjust = 1) +
    theme_minimal() +
    labs(title = "Binary Confusion Matrix", x = "Reference", y = "Predicted") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplotly(net_ggplot)

```

After building the model with an 80% training subset of the total dataset, we use it to predict values for the remaining 20%. We evaluate the model's performance using a confusion matrix, which allowe us to compare our predicted values with the actual values of the test subset. The model successfully classifies 10,098 dogs as pure-bred, with only 44 being misclassified. However, this good result is overshadowed by the misclassification of 4,020 mixed-breed dogs, with only 31 correct predictions. This suggests that the model wrongly tends to classify most dogs as pure-bred.

```{r neuralnetwork_quality, include=FALSE}

# Switch the type to "prob"
pred_prob <- predict(breed_net,
                    df_test,
                    decision.values=TRUE,
                    type = "prob")

# Extract probabilities of the positive class
pred_prob_positive <- pred_prob[, 2]

# Convert to a numeric vector
pred_numeric <- as.numeric(pred_prob_positive)

# Create the prediction object
pred <- ROCR::prediction(pred_numeric,
                         df_test$BinaryMixedBreed)


```



```{r neuralnetwork_ROC, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, results='hide', fig.align='center', include=TRUE, fig.width=8, fig.height=6, cache=TRUE}

perf <- ROCR::performance(pred, "tpr", "fpr")
plot(perf, lwd=2, col="darkseagreen", main = "ROC Curve")
abline(a=0, b=1)

```

The *ROC Curve* displays a closeness to the diagonal, which raises the possibility that the model’s predictions are not accurate, and support the need to either review the model with more predictors or consider a different model to answer the question at hand altogether.

---

### 3.6. Support Vector Machine Model

In the last chapter of our series on machine learning models we aim to predict the age group of dog owners based on the ages of their dogs at time of registration, for which we will implement a Support Vector Machine (SVM). As a preliminary step, observations belonging to both variables are seen to be assigned the numerical value 999, suggesting 'unknown'. In order to not exclude these points from the training and testing subsets, we assign them the mean value of the rest of the set.

``` {r svm_libraries, include=FALSE}

if (!require(e1071, quietly = TRUE)) {
  install.packages("e1071")
  library(e1071)
}

if (!require(MASS, quietly = TRUE)) {
  install.packages("MASS")
  library(MASS)
}

if (!require(caret, quietly = TRUE)) {
  install.packages("caret")
  library(caret)
}

if (!require(doParallel, quietly = TRUE)) {
  install.packages("doParallel")
  library(doParallel)
}

```

``` {r svm_prep, include=FALSE}

df_EN_svm <- df_EN

# Replacing dog age unknowns (999) with mean
mean_dog_age <- mean(df_EN_svm$DogAgeGroupCd[df_EN_svm$DogAgeGroupCd != 999], na.rm = TRUE)

df_EN_svm <- df_EN_svm %>%
  mutate(DogAgeGroupCd = ifelse(DogAgeGroupCd == 999, mean_dog_age, DogAgeGroupCd))

# Replacing owner age unknowns (999) with mean
mean_owner_age <- mean(df_EN_svm$OwnerAgeGroupCd[df_EN_svm$OwnerAgeGroupCd != 999], na.rm = TRUE)

df_EN_svm <- df_EN_svm %>%
  mutate(OwnerAgeGroupCd = ifelse(OwnerAgeGroupCd == 999, mean_owner_age, OwnerAgeGroupCd))

# For the following plots
count_data <- df_EN_svm %>% 
  group_by(DogAgeGroupCd, OwnerAgeGroupCd) %>% 
  summarize(count = n())

```

``` {r svm_plot1, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}

scatter_plot <- ggplot(count_data, aes(x = DogAgeGroupCd, y = OwnerAgeGroupCd, size = count)) +
  geom_point(color = "seagreen", alpha = 0.7) + 
  scale_size_continuous(range = c(4, 12)) + 
  labs(title = "Heatmap of Owner Age Group vs Dog Age Group",
       x = "Dog Age Group",
       y = "Owner Age Group") +
  theme_minimal()

ggplotly(scatter_plot)

```

As a prelude to the model building we can have a look at the above plot, which portrays the relationship between the relevant response and predictor variables. The size of the dots reflect the frequency of observations falling under such combination of age groups. The mean-assigned unknown observations stand out for not fitting onto the grid, reflecting their non-integer nature against the original integer values. Keeping them with their decimals was preferred, as assigning them to either one multiple of 10 value above or below was considered to be too much of an alteration of their values.

What becomes visible at a first glance is the concentration of values around the area corresponding to younger dogs and owners aged 30-40. We can expect more precise predictions around this cluster based on this assumption.

For model evaluation, these numbers are cast back to integers, and then to factors to produce interpretable confusion matrices. It is worth noting that these preparation measures could be undertaken in many different ways, with potential improvements on the models. We will leave such considerations for future iterations of the research project, and concentrate on developing the models with the main purpose of becoming aquainted with the relevant tools and evaluation methods.

#### 3.6.1. SVM with linear kernel function

``` {r svm_sampling_settings, include=FALSE}

set.seed(123)
intrain <- createDataPartition(y = df_EN_svm$OwnerAgeGroupCd, p = 0.7, list = FALSE)
training <- df_EN_svm[intrain, ]
testing <- df_EN_svm[-intrain, ]

trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3, verboseIter = TRUE)

```

With the help of the `caret` framework we implement model building functions from the `e1071` library, along with easy tuning and training control methods. The data is initially sampled into proportional 70% training and 30% testing sets. Additionally, a 10-fold cross-validation optimization procedure is implemented, with 3 repetitions.

``` {r svm_linear_tr, include=FALSE}

file_path <- "ML1_Final_Dogs_cache/svm/svm_linear_model.rds"

if (!file.exists(file_path)) {
    # If the file doesn't exist, execute SVM model
    svm_linear <- train(OwnerAgeGroupCd ~ DogAgeGroupCd,
                        data = training,
                        method = "svmLinear",
                        trControl = trctrl,
                        trace = TRUE,
                        tuneLength = 10)

    saveRDS(svm_linear, file = file_path)
} else {
    # If the file exists, load the model
    svm_linear <- readRDS(file_path)
}

```

``` {r svm_linear_sum, fig.align='center', include=TRUE, fig.width=8, fig.height=6, cache=TRUE, echo=TRUE}

svm_linear

```

The chosen model with linear kernel function is assigned a cost parameter of 1. We now go ahead and look at the results.

``` {r svm_linear_confusion, include=FALSE, cache=TRUE}

truth = round(testing$OwnerAgeGroupCd, -1)

# Predictions on testing data
predictions <- predict(svm_linear, testing)
predictions <- round(predict(svm_linear, testing), -1) # Round to nearest x10

# Create a table of predicted vs. true values using the testing data
misclass <- table(predictions, truth)
misclass

# Convert misclass to a data frame
misclass_df <- as.data.frame.table(misclass)

confMa_linear <- confusionMatrix(as.factor(predictions), 
                                 as.factor(truth))

```

The predicted results have been adjusted and rounded to their nearest multiple of 10, in order to be able to visualize them against the actual decade time ranges represented in the original data. The following confusion plot shows the frequency of guesses for each age range.

``` {r svm_linear_confusion_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}

svm_linear_conf <- ggplot(misclass_df, aes(x = truth, y = predictions, fill = Freq)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "seagreen") +
  theme_minimal() +
  labs(title = "Confusion Matrix - SVM Linear Kernel",
       x = "Reference",
       y = "Prediction",
       fill = "Frequency")

ggplotly(svm_linear_conf)

confMa_linear <- confusionMatrix(as.factor(predictions), 
                                 as.factor(truth))

```

The above plot shows all predictions fall exclussively under the 40-60 owner age ranges, with most guesses corresponding to 40. Although the results are relatively poor, the model does capture the main owner demographic being the owners aged 30 to 40.

``` {r svm_linear_matrix, echo=TRUE}

confMa_linear

```

A closer look at the confusion matrix shows the accuracy is quite low, at 23%. We opt for changing the kernel function, as it may capture additional relevant patterns in the data.

---

#### 3.6.2. SVM with radial kernel function

``` {r svm_radial_tr, include=FALSE}

file_path <- "ML1_Final_Dogs_cache/svm/svm_radial_model.rds"

if (!file.exists(file_path)) {
    # If the file doesn't exist, execute SVM model
    svm_rbf <- train(OwnerAgeGroupCd ~ DogAgeGroupCd,
                     data = training,
                     method = "svmRadial",
                     trControl = trctrl,
                     trace = TRUE,
                     tuneLength = 10)

    saveRDS(svm_rbf, file = file_path)
} else {
    # If the file exists, load the model
    svm_rbf <- readRDS(file_path)
}

```

``` {r svm_radial_sum, fig.align='center', include=TRUE, fig.width=8, fig.height=6, cache=TRUE, echo=TRUE}

svm_rbf

```

The radial kernel SVM model is built with similar characteristics to the linear one, with a sigma parameter valued at 8.77.

``` {r svm_radial_confusion, include=FALSE, warning=FALSE}

if (!file.exists("ML1_Final_Dogs_cache/svm/svm_rbf_misclass.rds")) {
  
  predictions <- predict(svm_rbf, testing)
  predictions <- round(predict(svm_rbf, testing), -1) # Round to nearest x10
  
  # Create a table of predicted vs. true values
  misclass <- table(predictions, truth)
  misclass_df <- as.data.frame.table(misclass)
  
  # Save the data frame to an .RDS file
  saveRDS(misclass_df, file = "ML1_Final_Dogs_cache/svm/svm_rbf_misclass.rds")
  
} else {
  
  # Load the data frame from the .RDS file
  misclass_df <- readRDS("ML1_Final_Dogs_cache/svm/svm_rbf_misclass.rds")
}

confMa_radial <- confusionMatrix(as.factor(predictions), 
                                 as.factor(truth))

```

``` {r svm_radial_confusion_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}

svm_radial_conf <- ggplot(misclass_df, aes(x = truth, y = predictions, fill = Freq)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "turquoise4") +
  theme_minimal() +
  labs(title = "Confusion Matrix - SVM Radial Kernel",
       x = "Reference",
       y = "Prediction",
       fill = "Frequency")

ggplotly(svm_radial_conf)

```

The confusion matrix in this case follows an almost identical pattern, with very slight differences in frequencies. It again is limited to the 40-60 age ranges, and captures most intensely the most populated demographic sector.

``` {r svm_radial_matrix, echo=TRUE}

confMa_radial

```

The results from the confusion matrix of the second model show an identical accuracy of 23% The following suggestions can be made based on both results for a further development of the study:

- Closer attention could be dedicated to the original structure of the data during preparation, regarding the type treatment of the variables and outliers.
- The sampling method could be optimized, with a different proportion of training vs. testing data subsets.
- Alternative tuning settings may allow for further finetuning of the models.
- Perhaps the nature of the data, which despite its numeric format had a very discrete nature, gives way to ambiguities and limits the prediction potential of the models.
- Perhaps this specific research question is better answered with a different model.

---

## 4. Additional chapter

### 4.1. Dataset translation

A noteworthy addition to the construction and testing of diverse machine learning models pertains to the methodology employed, particularly within the R programming environment. Given that our data science team consists of three members from different cultural and professional backgrounds, we prioritized making the dataset accessible to everyone. This led us to dedicate a chapter in the early phases of the project to translating the dataset into English.

In today's dynamic field of data science, our experience has shown us that R is the go-to language for machine learning and statistical analysis, while Python dominates a wider array of applications. As Python enthusiasts, crafting an efficient yet straightforward translation script in R seemed daunting at first, pushing us beyond our comfort zone. This experience turned into an intricate exercise, allowing us to deepen our fluency in R through practical application of code patterns like conditional statements, loops, and function declarations. It became a valuable opportunity to expand our skills and reinforce our understanding of R's unique capabilities.

We will now provide a brief explanation of the logic and implementation of this translation script. The translation focused on names of columns and key patterns found within the categorical responses. These were defined manually by the members of the team able to work in German.

A simple function declaration looked for patterns in the text components of the variable responses, that could seamlessly be translated to English without minute interventions.

```rverbatim
replace_patterns <- function(text, patterns, replacements) {
  for (i in seq_along(patterns)) {
    text <- str_replace_all(text, patterns[i], replacements[i])
  }
  return(text)
}
```
Such patterns would take the following form:

```rverbatim
patterns <- c("- bis ", "-Jährige", "männlich", "weiblich", ...)
replacements <- c(" to ", " years old", "male", "female", ...)
```
The only remaining complex task was replacing the dog names with their English words:

```rverbatim
color_patterns <- c("schwarz", "braun", "weiss", "grau", ...)
color_replacements <- c("black", "brown", "white", "gray", ...)

df_EN$DogColor <- replace_patterns(df_EN$DogColor, color_patterns, color_replacements)
```

Lastly, dog breeds were deliberately chosen to be left in their original form, given their complex descriptive nature, as well as the vast dimensionality of that variable.

---

### 4.2. Interactive plots and UI elements

A noteworthy aspect of our project was the emphasis on integrating data-driven research with a clean and sophisticated user-friendly interface. To achieve this, we extensively utilized the Shiny Apps framework, particularly in the Exploratory Data Analysis section of our report. This focus was crucial for directing us towards a correct understanding of the data and its underlying patterns, enabling us to formulate the right questions and match them with the most appropriate tools.

In addition to Shiny Apps, many of the plots generated with the ggplot2 library were made interactive through the implementation of the Plotly framework. This interactivity enhanced the analytical capabilities and accessibility of our visualizations, making them more informative and engaging for users.

A significant challenge we faced was producing an efficient RMarkdown script and integrating chapters developed by individual team members. Our collaboration platform of choice was GitHub, where we maintained an organized and intuitive directory structure. To streamline the knitting process, we cached some of the most complex models and elements manually, storing them efficiently within the agreed folder structure. This approach minimized computational load and improved the reproducibility of our work.

We believe a successful data science project should balance robust data interpretation and coding with accessible, user-friendly presentation platforms for non-technical clients and stakeholders. Just as with machine learning methods, the applications we develop should aim for maximum reproducibility and intuitiveness, ensuring they are as effective and user-friendly as possible.

---

## 5. Conclusion

To summarize the insights and observations made during the project's development, we will now reflect on the insights obtained as well as the challenges encountered.

### 5.1. Key points for Pet Paradise

*Age & Neighborhood*

Several of the presented statistical models prove that districts 11, 7 and 9 lead the dog demographics charts, and maintain a steady but ever-developing growth, which is parallel to the their human population's development. It is no coincidance that these are sectors of the city which have experienced recent urban development and influx of younger families. It is expected that this growth will continue in the coming years, leading us to suggest establishing Pet Paradise branches in those locations. 

These areas will also be subjected to an increasing number of registrations of younger dogs in the coming years, as a side effect of generational renewal. Subsequently, younger canines demand a choice of toys and accessories promoting physical activity and mental canine stimulation. We recommend a strategically curated collection of toys, agility equipment, and puzzle feeders to cater to energetic young dogs. Large dog populations are also prone to an increase of aging dogs in the coming years, for which we recommend Pet Paradise provides products that include joint supplements, vitamins, and specialized diets tailored to older dogs' needs, extending the dog’s health and vitality.

*Breed-specific Services*

A recurrent lesson obtained from our machine learning models pertains to the growing popularity of certain dog breeds. Particularly, our GAM model clearly outlined a growing registration count of Labrador retrievers, along with Chihuahuas, Yorkshire terriers, Jack Russel terriers and Maltese dogs. The growing preference for dogs of such characteristics should support business choices regarding breed-specific products and services.

We recommend devising special marketing designed for owners of dogs that may have special fur requirements, such as the Labrador terrier or Yorkshire terrier. Also, high-energy breeds like Jack Russel terriers will require special grooming and nutritional products. So offering a range of coat shampoos and grooming essentials tailored to different fur types will be of strategical importance for the brand. We believe, providing breed-specific expertise can differentiate Pet Paradise and attract customers in prime locations.

---

### 5.2. A comment on the dataset

The dataset chosen presented a series of particular hurdles from the beginning. Although conceptually interesting and complex in its structure, it mainly comprises categorical descriptors with varying levels of dimensionality. A notable example are the dog breeds and breed mixes, which encompass more than 300 possible levels. On an opposite note, the few  numerical original variables are highly 'discrete' in nature, consisting of integer values within narrow ranges, lacking in granularity. Such is the case of the age groups of both dogs and owners. This discrepancy posed interesting challenges, that required more unconventional approaches.

Such characteristics in the data provided an opportunity to focus the research on interpreting grouped counts of items and their relationships with others, allowing us to devise research questions that leveraged this data quality. The effort generally followed the traditional sequence of posing a question and then identifying the appropriate method to answer it. This approach became more challenging with complex models, where the process often seemed reversed.

The most significant challenge was building complex models, specifically the artificial neural networks and support vector machines, which typically perform better with complex numeric relationships and more quantitative data. These observations support the frequently stated notion that simpler models often perform better with simpler datasets and are usually the best choice for addressing the research questions posed.

---

## 6. Appendix

---

### 6.1. Working with generative AI tools

Recognizing that generative AI tools are here to stay as invaluable companions for present and future data scientists, we leveraged these tools for support and proof-checking, significantly boosting our productivity. While AI quickly generated syntactically correct code solutions, we found that a solid understanding of the packages and general R workflows remained essential. This blend of AI assistance and deep domain knowledge allowed us to work more efficiently and effectively. Perhaps the most important aspect of working with such tools is being aware of their limitations, and the importance of promt engineering. Correctly stating the questions, with technical remarks and references to previous code, is for now the only way of guiding the LLM towards any useful solution to problems.

Following are examples of features and use cases:

#### Faulty plots and screenshots

Our primary tools for assistance were ChatGPT versions 3.5 and 4. The latter, boasting an image reader and direct CSV loader, revolutionized our troubleshooting process. This feature enabled us to interpret screenshots of sample plots and identify faulty ones, providing crucial context for prompted questions. With this capability, we could delve deeper into understanding the nuances of the issues at hand, ultimately leading to more informed decisions and efficient problem-solving.

#### Code adaptation

One particularly beneficial application of generative AI coding solutions emerged when integrating code developed by different team members. Each member had worked with local versions of the dataframes, following different naming conventions. In these instances, we would copy the relevant code snippets into the LLM prompt and request the replacement of specific variable names with the standardized ones from the main RMarkdown report. We also made sure to instruct the LLM not to alter any user-made comments and annotations, ensuring that the original context and insights were preserved. This approach streamlined the integration process, making collaboration more seamless and efficient.

#### Converting ggplot2 plots to plotly objects

Another simple use case of AI generated code was found in the process of converting a custom-coded ggplot object into an interactive plotly, by asking the LLM to store the object in a separate variable, and adding a `ggplotly()` call afterwards. This way, plots could be produced and tested as regular ggplot objects by the team members in separate script files, before being sent to the main report script and implemented as interactive applications.

#### Troubleshooting during knitting

Another scenario where ChatGPT proved invaluable was during troubleshooting sessions throughout the creation of the RMarkdown report. As various team members contributed code to the main script, errors frequently interrupted the knitting process. Moreover, the rendering framework for RMarkdown lacked the detailed outputs provided by RStudio's built-in console, often offering only the location of the faulty code and a vague description of the issue. Through the interpretation provided by ChatGPT, coupled with a copy of the problematic code snippet, pinpointing and locating these issues became much simpler. This guidance led us to a stage where, armed with insights from ChatGPT, we could implement solutions manually, enhancing our understanding and proficiency in the process.

---

## 7. References