unique_population_per_neighbourhood_group,
by = "neighbourhood_group")
data_grouped_with_population$proportion <- data_grouped_with_population$count / data_grouped_with_population$Total_Population
data_grouped_with_population$proportion_percent <- data_grouped_with_population$proportion * 100
# Barplot in ggplot2 as percentages
ggplot(data_grouped_with_population, aes(x = reorder(neighbourhood_group, proportion_percent), y = proportion_percent)) +
geom_bar(stat = "identity", fill = "#f1796f") +
theme_minimal() +
labs(title = "Airbnb listings per 100 residents by neighbourhood group",
subtitle = "Barcelona",
x = "Neighbourhood group",
y = "Percentage (%)") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Summarize the data to count the number of each property type
property_counts <- Barcelona_md %>%
group_by(room_type) %>%
summarise(quantity = n())
# Create the bar plot
ggplot(property_counts,
aes(x = reorder(room_type, quantity),
y = quantity,
fill = 'red')) +
geom_bar(stat = "identity") +
geom_text(aes(label = quantity),
hjust = 0,
size = 3) +
labs(x = "",
y = "Count",
title = "Room type count",
subtitle = "Barcelona") +
coord_flip() + # Flip the plot to horizontal bars
guides(fill = FALSE) +  # Remove the legend
theme_minimal()
ggplot(Barcelona_md, aes(x = neighbourhood_group)) +
geom_bar(aes(fill = room_type), position = "dodge") +
facet_wrap(~ room_type, scales = "free_y", nrow = 2) +
theme_minimal() +
labs(title = "Acommodation type by neighbourhood group",
subtitle = "Barcelona",
x = "Neighbourhood group",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1))
license_count <- Barcelona_md %>%
group_by(LicenseGrouping) %>%
summarise(quantity = n())
# Create the bar plot
ggplot(license_count,
aes(x = reorder(LicenseGrouping, quantity),
y = quantity,
fill = 'red')) +
geom_bar(stat = "identity") +
labs(x = "",
y = "Count",
title = "License status",
subtitle = "Barcelona") +
geom_text(aes(label = quantity),
hjust = 0,
size = 3) +
theme_minimal() +
coord_flip() + # Flip the plot to horizontal bars
guides(fill = FALSE)  # Remove the legend
tenant_count <- tenants %>%
group_by(TenantSizeGrouping) %>%
summarise(listing_count = n())
# Host numbers: great vs. small tenants
plotA <- ggplot(tenant_count,
aes(x = TenantSizeGrouping,
y = listing_count,
fill = "red")) +
geom_bar(stat = "identity") +
labs(x = "",
y = "Host count",
title = "Large vs. small tenants - Host count",
subtitle = "Barcelona") +
geom_text(aes(label = listing_count),
hjust = 0,
size = 3) +
theme_minimal() +
coord_flip() + # Flip the plot to horizontal bars
guides(fill = FALSE)  # Remove the legend
# Listing numbers: great vs. small tenants
tenant_count <- Barcelona_md %>%
group_by(TenantSizeGrouping) %>%
summarise(quantity = n())
plotB <- ggplot(tenant_count,
aes(x = TenantSizeGrouping,
y = quantity,
fill = 'red')) +
geom_bar(stat = "identity") +
labs(x = "",
y = "Listing Count",
title = "Large vs. small tenants - Listing count",
subtitle = "Barcelona") +
geom_text(aes(label = quantity),
hjust = 0,
size = 3) +
theme_minimal() +
coord_flip() + # Flip the plot to horizontal bars
guides(fill = FALSE)  # Remove the legend
grid.arrange(plotA, plotB, ncol = 1)
listings_per_host <- Barcelona_md %>%
group_by(host_id) %>%
summarize(count = n(), .groups = 'drop') %>%
filter(!is.na(host_id))
# Group all counts of 10 or more into '10+'
listings_per_host$count_grouped <- ifelse(listings_per_host$count > 10,
"10+",
as.character(listings_per_host$count))
# Convert the column to a factor to control the order in the plot
listings_per_host$count_grouped <- factor(listings_per_host$count_grouped,
levels = c(as.character(1:10),
"10+"))
# Create the histogram
ggplot(listings_per_host, aes(x = count_grouped)) +
geom_bar(fill = "#f1796f") +
labs(x = "Listing count",
y = "Number of hosts",
title = "Number of hosts per listing count",
subtitle = "Barcelona") +
theme(axis.text.x = element_text()) +
theme_minimal()
top_hosts <- Barcelona_md %>%
distinct(host_id, .keep_all = TRUE) %>%
arrange(desc(calculated_host_listings_count)) %>%
slice_head(n = 5)
# Create the ggplot2 horizontal barplot
ggplot(top_hosts, aes(x = reorder(host_name, calculated_host_listings_count),
y = calculated_host_listings_count)) +
geom_bar(stat = "identity",
fill = "#f1796f") +
geom_text(aes(label = calculated_host_listings_count),
hjust = 0,
color = "black",
size = 3) +
labs(title = "Top 5 hosts by number of listings",
subtitle = "Barcelona",
x = "",
y = "Listing count") +
coord_flip() + # Flip the plot to horizontal bars
theme_minimal() +
theme(axis.text.x = element_text(angle = 0, hjust = 1))
top_hosts <- Barcelona_md %>%
distinct(host_id, .keep_all = TRUE) %>%
arrange(desc(calculated_host_listings_count)) %>%
slice_head(n = 5)
# Create the ggplot2 horizontal barplot
ggplot(top_hosts, aes(x = reorder(host_name, calculated_host_listings_count),
y = calculated_host_listings_count)) +
geom_bar(stat = "identity",
fill = "#f1796f") +
geom_text(aes(label = calculated_host_listings_count),
hjust = 0,
color = "black",
size = 3) +
labs(title = "Top 5 hosts by number of listings",
subtitle = "Barcelona",
x = "",
y = "Listing count") +
coord_flip() + # Flip the plot to horizontal bars
theme_minimal() +
theme(axis.text.x = element_text(angle = 0, hjust = 1))
knitr::opts_chunk$set(echo = TRUE)
lm(price ~ star_rating, data = Barcelona_md)
data(co2)
data(co2)
co2.stl <- stl(co2, s.window = "periodic")
plot(co2.stl)
# 4) gam.xray -- 16% TRUE ??
xray.gam.acc <- cbind(
predict(gam.xray, type = "response"),
d.xray["disease"]
)
set.seed(10)
##### Packages #####
library(tidyverse)    # Data manipulation and visualization
library(kernlab)      # SVM methodology
library(e1071)        # SVM methodology
library(ISLR)         # Contains example data set
library(RColorBrewer) # Customized colors for plots
# Construct sample data set - completely separated
x <- matrix(rnorm(20*2), ncol = 2)
y <- c(rep(-1,10), rep(1,10))
x[y==1,] <- x[y==1,] + 2
dat <- data.frame(x=x, y=as.factor(y))
# Plot data
ggplot(
data = dat,
aes(x = x.2, y = x.1, color = y, shape = y)
) +
geom_point(size = 2) +
scale_color_manual(values=c("#000000", "#FF0000")) +
theme(legend.position = "none")
## Using the e1071 package
# Fit Support Vector Machine model to data set
svmfit <- svm(
y~., data = dat,
kernel = "linear", scale = FALSE,
cost = 1e10
)
# Plot Results
plot(svmfit, dat)
plot(t.yields)
##### EXERCISE 6.1 #####
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
pacf(t.yields, ylim = c(-1, 1))
## c)
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
r.burg$resid
str(r.burg
str(r.burg)
str(r.burg)
plot(resid)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
plot(resid)
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
##### EXERCISE 6.1 #####
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
pacf(t.yields, ylim = c(-1, 1))
# The exponential decay in the acf shows it may be an AR
# From the pacf we conclude p=1
# Xt − μ = α1(Xt−1 − μ) + Et
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
## c)
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
plot(resid)
par(mfrow = c(1, 2))
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
par(mfrow = c(1, 1))
##### EXERCISE 6.1 #####
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
pacf(t.yields, ylim = c(-1, 1))
# The exponential decay in the acf shows it may be an AR
# From the pacf we conclude p=1
# Xt − μ = α1(Xt−1 − μ) + Et
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
## c)
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
plot(resid)
par(mfrow = c(1, 2))
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
par(mfrow = c(1, 1))
par(mfrow = c(1, 1))
##### EXERCISE 6.1 #####
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
pacf(t.yields, ylim = c(-1, 1))
# The exponential decay in the acf shows it may be an AR
# From the pacf we conclude p=1
# Xt − μ = α1(Xt−1 − μ) + Et
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
## c)
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
par(mfrow = c(1, 1))
plot(resid)
par(mfrow = c(1, 2))
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
par(mfrow = c(1, 1))
## d)
str(r.mle <- ar(t.yields, method = "mle", order.max = 1))
r.mle <- arima(yields, order = c(1, 0, 0), include.mean = T)
r.mle
# The following will indicate if the algorithm has converged
r.mle$code
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
##### EXERCISE 6.1 #####
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
pacf(t.yields, ylim = c(-1, 1))
# The exponential decay in the acf shows it may be an AR
# From the pacf we conclude p=1
# Xt − μ = α1(Xt−1 − μ) + Et
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
## c)
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
par(mfrow = c(1, 1))
plot(resid)
par(mfrow = c(1, 2))
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
par(mfrow = c(1, 1))
## d)
str(r.mle <- ar(t.yields, method = "mle", order.max = 1))
r.mle <- arima(yields, order = c(1, 0, 0), include.mean = T)
r.mle
# The following will indicate if the algorithm has converged
r.mle$code
# 0 means there has been convergence
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
source("~/HSLU/24.1 Second Semester/W.MSCIDS_RTP02.F24 - Discrete Response, Time Series and Panel Data/Exercises/Exercise_06/Exercise-06.R", echo=TRUE)
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
par(mfrow = c(1, 1))
plot(resid)
par(mfrow = c(1, 2))
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
par(mfrow = c(1, 1))
## d)
str(r.mle <- ar(t.yields, method = "mle", order.max = 1))
r.mle <- arima(yields, order = c(1, 0, 0), include.mean = T)
r.mle
# The following will indicate if the algorithm has converged
r.mle$code
setwd("~/GitHub/MachineLearningMethods")
